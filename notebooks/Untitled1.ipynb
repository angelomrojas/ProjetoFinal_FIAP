{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6494f6fe-a431-4247-b947-2f228ed31807",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id               titulo              categoria        data  engajamento  \\\n",
      "1   2  Exploração em Marte    Astronomia e Espaço  2025-02-20          150   \n",
      "3   4             Redes 6G  Tecnologia e Internet  2025-02-23          110   \n",
      "\n",
      "   score  \n",
      "1    0.0  \n",
      "3    0.0  \n",
      "   id               titulo                           categoria        data  \\\n",
      "1   2  Exploração em Marte                 Astronomia e Espaço  2025-02-20   \n",
      "0   1        Avanços em IA  Inteligência Artificial e Inovação  2025-02-25   \n",
      "3   4             Redes 6G               Tecnologia e Internet  2025-02-23   \n",
      "\n",
      "   engajamento  score  \n",
      "1          150    0.0  \n",
      "0          120    0.5  \n",
      "3          110    0.0  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Criando dataset de notícias\n",
    "noticias = pd.DataFrame([\n",
    "    {\"id\": 1, \"titulo\": \"Avanços em IA\", \"categoria\": \"Inteligência Artificial e Inovação\", \"data\": \"2025-02-25\", \"engajamento\": 120},\n",
    "    {\"id\": 2, \"titulo\": \"Exploração em Marte\", \"categoria\": \"Astronomia e Espaço\", \"data\": \"2025-02-20\", \"engajamento\": 150},\n",
    "    {\"id\": 3, \"titulo\": \"Novo material supercondutor\", \"categoria\": \"Pesquisas Científicas\", \"data\": \"2025-02-22\", \"engajamento\": 80},\n",
    "    {\"id\": 4, \"titulo\": \"Redes 6G\", \"categoria\": \"Tecnologia e Internet\", \"data\": \"2025-02-23\", \"engajamento\": 110}\n",
    "])\n",
    "\n",
    "# Criando dataset de usuários e histórico de leitura\n",
    "usuarios = pd.DataFrame([\n",
    "    {\"user_id\": 1, \"noticias_lidas\": [1, 3]},\n",
    "    {\"user_id\": 2, \"noticias_lidas\": [2]},\n",
    "    {\"user_id\": 3, \"noticias_lidas\": []}  # Usuário novo (cold start)\n",
    "])\n",
    "\n",
    "# Modelo de recomendação baseado em conteúdo\n",
    "def recomendar_noticias(user_id, top_n=3):\n",
    "    usuario = usuarios[usuarios[\"user_id\"] == user_id].iloc[0]\n",
    "    noticias_lidas = usuario[\"noticias_lidas\"]\n",
    "    \n",
    "    if not noticias_lidas:  # Cold start\n",
    "        return noticias.sort_values(by=\"engajamento\", ascending=False).head(top_n)\n",
    "    \n",
    "    # Vetorização TF-IDF das categorias\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    matriz_tfidf = vectorizer.fit_transform(noticias[\"categoria\"])\n",
    "    \n",
    "    # Similaridade entre notícias lidas e todas as outras\n",
    "    sim_matrix = cosine_similarity(matriz_tfidf)\n",
    "    \n",
    "    # Encontrando as notícias mais similares\n",
    "    indices_lidas = [noticias[noticias[\"id\"] == n].index[0] for n in noticias_lidas]\n",
    "    scores = sim_matrix[indices_lidas].mean(axis=0)\n",
    "    \n",
    "    # Ordenar notícias mais similares (excluindo já lidas)\n",
    "    noticias[\"score\"] = scores\n",
    "    recomendadas = noticias[~noticias[\"id\"].isin(noticias_lidas)].sort_values(by=\"score\", ascending=False)\n",
    "    \n",
    "    return recomendadas.head(top_n)\n",
    "\n",
    "# Testando recomendação\n",
    "print(recomendar_noticias(1))\n",
    "print(recomendar_noticias(3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a03d784-a864-4957-9fb7-4acda86d97af",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = recomendar_noticias(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b5cd1c25-acd7-4c1e-9749-28136c9594d2",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'lightfm'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msqlite3\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlightfm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LightFM\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlightfm\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dataset\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdatetime\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m datetime\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'lightfm'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import sqlite3\n",
    "from lightfm import LightFM\n",
    "from lightfm.data import Dataset\n",
    "from datetime import datetime\n",
    "\n",
    "# Simulação de dados de interações (usuário, notícia, porcentagem de leitura)\n",
    "leituras = [\n",
    "    (1, 101, 75.0), (1, 102, 50.0), (1, 103, 10.0),\n",
    "    (2, 101, 80.0), (2, 104, 90.0), (2, 105, 60.0),\n",
    "    (3, 102, 70.0), (3, 103, 40.0), (3, 105, 20.0)\n",
    "]\n",
    "\n",
    "# Simulação de dados de notícias (id, tema, data de publicação)\n",
    "noticias = {\n",
    "    101: (\"Crime e Justiça\", \"2025-02-20\"),\n",
    "    102: (\"Economia\", \"2025-02-18\"),\n",
    "    103: (\"Política\", \"2025-02-17\"),\n",
    "    104: (\"Crime e Justiça\", \"2025-02-22\"),\n",
    "    105: (\"Tecnologia\", \"2025-02-15\")\n",
    "}\n",
    "\n",
    "# Criando dataset para o LightFM\n",
    "dataset = Dataset()\n",
    "users = set(l[0] for l in leituras)\n",
    "items = set(l[1] for l in leituras)\n",
    "dataset.fit(users, items)\n",
    "\n",
    "# Criando a matriz de interações (usando porcentagem de leitura como peso)\n",
    "(interactions_matrix, _, _) = dataset.build_interactions(((u, i, s / 100) for u, i, s in leituras))\n",
    "\n",
    "# Treinando o modelo\n",
    "model = LightFM(loss='warp')\n",
    "model.fit(interactions_matrix, epochs=10, num_threads=2)\n",
    "\n",
    "# Função para recomendar notícias mais recentes do melhor tema para um usuário\n",
    "def recommend_news(model, dataset, user_id, noticias, n=3):\n",
    "    user_internal_id = dataset.mapping()[\"user_id_mapping\"].get(user_id)\n",
    "    if user_internal_id is None:\n",
    "        return \"Usuário não encontrado.\"\n",
    "    \n",
    "    all_items = list(dataset.mapping()[\"item_id_mapping\"].values())\n",
    "    scores = model.predict(user_internal_id, all_items)\n",
    "    ranked_items = np.argsort(-scores)\n",
    "    \n",
    "    item_reverse_mapping = {v: k for k, v in dataset.mapping()[\"item_id_mapping\"].items()}\n",
    "    ranked_news_ids = [item_reverse_mapping[i] for i in ranked_items]\n",
    "    \n",
    "    # Determinar o melhor tema com base na interação do usuário\n",
    "    temas_interacoes = {}\n",
    "    for noticia_id in ranked_news_ids:\n",
    "        tema, data_pub = noticias[noticia_id]\n",
    "        if tema not in temas_interacoes:\n",
    "            temas_interacoes[tema] = []\n",
    "        temas_interacoes[tema].append((noticia_id, datetime.strptime(data_pub, \"%Y-%m-%d\")))\n",
    "    \n",
    "    # Escolher o tema mais relevante e recomendar as notícias mais recentes\n",
    "    melhor_tema = max(temas_interacoes, key=lambda t: len(temas_interacoes[t]))\n",
    "    noticias_relevantes = sorted(temas_interacoes[melhor_tema], key=lambda x: x[1], reverse=True)[:n]\n",
    "    \n",
    "    return [noticia_id for noticia_id, _ in noticias_relevantes]\n",
    "\n",
    "# Exemplo de recomendação para um usuário\n",
    "user_id = 1\n",
    "recommended_news = recommend_news(model, dataset, user_id, noticias)\n",
    "print(f\"Notícias recomendadas para o usuário {user_id}: {recommended_news}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6cca1291-56a4-4ca4-aa47-738fa799378c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sqlite3\n",
    "import pickle\n",
    "from sklearn.decomposition import NMF\n",
    "from scipy.sparse import csr_matrix\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5ec9e20e-295f-44cb-bcfc-851bd87687a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo carregado com sucesso.\n",
      "Notícias recomendadas para o usuário 1: [104, 101]\n",
      "Notícias recomendadas para o novo usuário 99: [104, 101, 102]\n",
      "Modelo atualizado com novas interações e salvo.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import sqlite3\n",
    "import pickle\n",
    "from sklearn.decomposition import NMF\n",
    "from scipy.sparse import csr_matrix\n",
    "from datetime import datetime\n",
    "\n",
    "# Simulação de dados de interações (usuário, notícia, porcentagem de leitura)\n",
    "leituras = [\n",
    "    (1, 101, 75.0), (1, 102, 50.0), (1, 103, 10.0),\n",
    "    (2, 101, 80.0), (2, 104, 90.0), (2, 105, 60.0),\n",
    "    (3, 102, 70.0), (3, 103, 40.0), (3, 105, 20.0)\n",
    "]\n",
    "\n",
    "# Simulação de dados de notícias (id, tema, data de publicação)\n",
    "noticias = {\n",
    "    101: (\"Crime e Justiça\", \"2025-02-20\"),\n",
    "    102: (\"Economia\", \"2025-02-18\"),\n",
    "    103: (\"Política\", \"2025-02-17\"),\n",
    "    104: (\"Crime e Justiça\", \"2025-02-22\"),\n",
    "    105: (\"Tecnologia\", \"2025-02-15\")\n",
    "}\n",
    "\n",
    "# Criando mapeamento de índices\n",
    "usuarios = list(set(l[0] for l in leituras))\n",
    "noticias_ids = list(set(l[1] for l in leituras))\n",
    "user_map = {u: i for i, u in enumerate(usuarios)}\n",
    "noticia_map = {n: i for i, n in enumerate(noticias_ids)}\n",
    "\n",
    "# Criando a matriz de interações\n",
    "num_users = len(usuarios)\n",
    "num_noticias = len(noticias_ids)\n",
    "matriz_interacoes = np.zeros((num_users, num_noticias))\n",
    "for u, n, s in leituras:\n",
    "    matriz_interacoes[user_map[u], noticia_map[n]] = s / 100\n",
    "\n",
    "# Treinando o modelo NMF\n",
    "def train_model(matriz_interacoes):\n",
    "    model = NMF(n_components=5, init='random', random_state=42)\n",
    "    W = model.fit_transform(matriz_interacoes)\n",
    "    H = model.components_\n",
    "    \n",
    "    with open(\"nmf_model.pkl\", \"wb\") as f:\n",
    "        pickle.dump((model, W, H), f)\n",
    "    return model, W, H\n",
    "\n",
    "# Carregar modelo salvo ou treinar um novo\n",
    "try:\n",
    "    with open(\"nmf_model.pkl\", \"rb\") as f:\n",
    "        model, W, H = pickle.load(f)\n",
    "    print(\"Modelo carregado com sucesso.\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Modelo não encontrado. Treinando um novo...\")\n",
    "    model, W, H = train_model(matriz_interacoes)\n",
    "\n",
    "# Função para recomendar notícias\n",
    "def recommend_news(user_id, n=3):\n",
    "    if user_id not in user_map:\n",
    "        return recommend_popular_news(n)\n",
    "    \n",
    "    user_idx = user_map[user_id]\n",
    "    scores = np.dot(W[user_idx], H)\n",
    "    ranked_news_idx = np.argsort(scores)[::-1]\n",
    "    \n",
    "    temas_interacoes = {}\n",
    "    for idx in ranked_news_idx:\n",
    "        noticia_id = noticias_ids[idx]\n",
    "        tema, data_pub = noticias[noticia_id]\n",
    "        if tema not in temas_interacoes:\n",
    "            temas_interacoes[tema] = []\n",
    "        temas_interacoes[tema].append((noticia_id, datetime.strptime(data_pub, \"%Y-%m-%d\")))\n",
    "    \n",
    "    melhor_tema = max(temas_interacoes, key=lambda t: len(temas_interacoes[t]))\n",
    "    noticias_relevantes = sorted(temas_interacoes[melhor_tema], key=lambda x: x[1], reverse=True)[:n]\n",
    "    \n",
    "    return [noticia_id for noticia_id, _ in noticias_relevantes]\n",
    "\n",
    "# Recomendação para novos usuários baseada nas notícias mais populares\n",
    "def recommend_popular_news(n=3):\n",
    "    popularidade = {}\n",
    "    for _, noticia_id, leitura in leituras:\n",
    "        if noticia_id not in popularidade:\n",
    "            popularidade[noticia_id] = []\n",
    "        popularidade[noticia_id].append(leitura)\n",
    "    \n",
    "    media_popularidade = {k: np.mean(v) for k, v in popularidade.items()}\n",
    "    noticias_populares = sorted(media_popularidade.keys(), key=lambda x: (media_popularidade[x], noticias[x][1]), reverse=True)\n",
    "    \n",
    "    return noticias_populares[:n]\n",
    "\n",
    "# Atualizar modelo com novas interações\n",
    "def update_and_retrain(new_lectures):\n",
    "    global leituras, model, W, H, matriz_interacoes\n",
    "    leituras.extend(new_lectures)\n",
    "    matriz_interacoes = np.zeros((num_users, num_noticias))\n",
    "    for u, n, s in leituras:\n",
    "        matriz_interacoes[user_map[u], noticia_map[n]] = s / 100\n",
    "    model, W, H = train_model(matriz_interacoes)\n",
    "    print(\"Modelo atualizado com novas interações e salvo.\")\n",
    "\n",
    "# Exemplo de recomendação\n",
    "user_id = 1\n",
    "recommended_news = recommend_news(user_id)\n",
    "print(f\"Notícias recomendadas para o usuário {user_id}: {recommended_news}\")\n",
    "\n",
    "# Exemplo de recomendação para novo usuário\n",
    "new_user_id = 99\n",
    "recommended_news_new_user = recommend_news(new_user_id)\n",
    "print(f\"Notícias recomendadas para o novo usuário {new_user_id}: {recommended_news_new_user}\")\n",
    "\n",
    "# Exemplo de atualização do modelo\n",
    "new_data = [(1, 104, 85.0), (2, 102, 95.0)]\n",
    "update_and_retrain(new_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0e0dd57-f3cc-4807-84c3-a27854cc5643",
   "metadata": {},
   "source": [
    "https://chatgpt.com/share/67bf9194-65c0-8000-a1a9-33c08d728ad6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "85091a71-948c-4d96-9dda-c69288c33d34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo carregado com sucesso.\n",
      "Notícias recomendadas para o usuário 1: [104, 101]\n",
      "Notícias recomendadas para o usuário 2: [104, 101]\n",
      "Notícias recomendadas para o usuário 3: [104, 101]\n",
      "Notícias recomendadas para o usuário 4: [104, 101]\n",
      "Notícias recomendadas para o usuário 5: [104, 101]\n",
      "Notícias recomendadas para o novo usuário 99: [106, 104, 108]\n",
      "Modelo atualizado com novas interações e salvo.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import sqlite3\n",
    "import pickle\n",
    "from sklearn.decomposition import NMF\n",
    "from scipy.sparse import csr_matrix\n",
    "from datetime import datetime\n",
    "\n",
    "# Simulação de dados de interações (usuário, notícia, porcentagem de leitura)\n",
    "leituras = [\n",
    "    (1, 101, 75.0), (1, 102, 50.0), (1, 103, 10.0), (1, 106, 90.0),\n",
    "    (2, 101, 80.0), (2, 104, 90.0), (2, 105, 60.0), (2, 107, 70.0),\n",
    "    (3, 102, 70.0), (3, 103, 40.0), (3, 105, 20.0), (3, 108, 85.0),\n",
    "    (4, 101, 50.0), (4, 106, 95.0), (4, 107, 65.0), (4, 108, 75.0),\n",
    "    (5, 103, 90.0), (5, 104, 80.0), (5, 105, 70.0), (5, 109, 60.0),\n",
    "]\n",
    "\n",
    "# Simulação de dados de notícias (id, tema, data de publicação)\n",
    "noticias = {\n",
    "    101: (\"Crime e Justiça\", \"2025-02-20\"),\n",
    "    102: (\"Economia\", \"2025-02-18\"),\n",
    "    103: (\"Política\", \"2025-02-17\"),\n",
    "    104: (\"Crime e Justiça\", \"2025-02-22\"),\n",
    "    105: (\"Tecnologia\", \"2025-02-15\"),\n",
    "    106: (\"Saúde\", \"2025-02-21\"),\n",
    "    107: (\"Educação\", \"2025-02-19\"),\n",
    "    108: (\"Esportes\", \"2025-02-23\"),\n",
    "    109: (\"Música\", \"2025-02-16\")\n",
    "}\n",
    "\n",
    "# Criando mapeamento de índices\n",
    "usuarios = list(set(l[0] for l in leituras))\n",
    "noticias_ids = list(noticias.keys())\n",
    "user_map = {u: i for i, u in enumerate(usuarios)}\n",
    "noticia_map = {n: i for i, n in enumerate(noticias_ids)}\n",
    "\n",
    "# Criando a matriz de interações\n",
    "num_users = len(usuarios)\n",
    "num_noticias = len(noticias_ids)\n",
    "matriz_interacoes = np.zeros((num_users, num_noticias))\n",
    "for u, n, s in leituras:\n",
    "    matriz_interacoes[user_map[u], noticia_map[n]] = s / 100\n",
    "\n",
    "# Treinando o modelo NMF\n",
    "def train_model(matriz_interacoes):\n",
    "    model = NMF(n_components=5, init='random', random_state=42)\n",
    "    W = model.fit_transform(matriz_interacoes)\n",
    "    H = model.components_\n",
    "    \n",
    "    with open(\"nmf_model2.pkl\", \"wb\") as f:\n",
    "        pickle.dump((model, W, H), f)\n",
    "    return model, W, H\n",
    "\n",
    "# Carregar modelo salvo ou treinar um novo\n",
    "try:\n",
    "    with open(\"nmf_model2.pkl\", \"rb\") as f:\n",
    "        model, W, H = pickle.load(f)\n",
    "    print(\"Modelo carregado com sucesso.\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Modelo não encontrado. Treinando um novo...\")\n",
    "    model, W, H = train_model(matriz_interacoes)\n",
    "\n",
    "# Função para recomendar notícias\n",
    "def recommend_news(user_id, n=3):\n",
    "    if user_id not in user_map:\n",
    "        return recommend_popular_news(n)\n",
    "    \n",
    "    user_idx = user_map[user_id]\n",
    "    scores = np.dot(W[user_idx], H)\n",
    "    ranked_news_idx = np.argsort(scores)[::-1]\n",
    "    \n",
    "    temas_interacoes = {}\n",
    "    for idx in ranked_news_idx:\n",
    "        noticia_id = noticias_ids[idx]\n",
    "        tema, data_pub = noticias[noticia_id]\n",
    "        if tema not in temas_interacoes:\n",
    "            temas_interacoes[tema] = []\n",
    "        temas_interacoes[tema].append((noticia_id, datetime.strptime(data_pub, \"%Y-%m-%d\")))\n",
    "    \n",
    "    melhor_tema = max(temas_interacoes, key=lambda t: len(temas_interacoes[t]))\n",
    "    noticias_relevantes = sorted(temas_interacoes[melhor_tema], key=lambda x: x[1], reverse=True)[:n]\n",
    "    \n",
    "    return [noticia_id for noticia_id, _ in noticias_relevantes]\n",
    "\n",
    "# Recomendação para novos usuários baseada nas notícias mais populares\n",
    "def recommend_popular_news(n=3):\n",
    "    popularidade = {}\n",
    "    for _, noticia_id, leitura in leituras:\n",
    "        if noticia_id not in popularidade:\n",
    "            popularidade[noticia_id] = []\n",
    "        popularidade[noticia_id].append(leitura)\n",
    "    \n",
    "    media_popularidade = {k: np.mean(v) for k, v in popularidade.items()}\n",
    "    \n",
    "    todas_noticias = list(noticias.keys())\n",
    "\n",
    "    noticias_populares = sorted(\n",
    "        todas_noticias, \n",
    "        key=lambda x: (media_popularidade.get(x, 0), noticias[x][1]), \n",
    "        reverse=True\n",
    "    )\n",
    "    \n",
    "    return noticias_populares[:n]\n",
    "\n",
    "# Atualizar modelo com novas interações\n",
    "def update_and_retrain(new_lectures):\n",
    "    global leituras, model, W, H, matriz_interacoes\n",
    "    leituras.extend(new_lectures)\n",
    "    matriz_interacoes = np.zeros((num_users, num_noticias))\n",
    "    for u, n, s in leituras:\n",
    "        matriz_interacoes[user_map[u], noticia_map[n]] = s / 100\n",
    "    model, W, H = train_model(matriz_interacoes)\n",
    "    print(\"Modelo atualizado com novas interações e salvo.\")\n",
    "\n",
    "# Exemplo de recomendação\n",
    "for user_id in usuarios:\n",
    "    recommended_news = recommend_news(user_id)\n",
    "    print(f\"Notícias recomendadas para o usuário {user_id}: {recommended_news}\")\n",
    "\n",
    "# Exemplo de recomendação para novo usuário\n",
    "new_user_id = 99\n",
    "recommended_news_new_user = recommend_news(new_user_id)\n",
    "print(f\"Notícias recomendadas para o novo usuário {new_user_id}: {recommended_news_new_user}\")\n",
    "\n",
    "# Exemplo de atualização do modelo\n",
    "new_data = [(1, 104, 85.0), (2, 102, 95.0), (5, 107, 80.0), (4, 109, 90.0)]\n",
    "update_and_retrain(new_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "01b1e9fb-6536-4e35-b63b-2e2a0127a8aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo não encontrado. Treinando um novo...\n",
      "Usuário 99 adicionado com sucesso.\n",
      "Notícias recomendadas para o novo usuário 99: [104, 101]\n",
      "Notícia 110 adicionada com sucesso.\n",
      "A nova notícia 110 NÃO foi recomendada para o usuário 1.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import sqlite3\n",
    "import pickle\n",
    "from sklearn.decomposition import NMF\n",
    "from scipy.sparse import csr_matrix\n",
    "from datetime import datetime\n",
    "\n",
    "# Simulação de dados de interações (usuário, notícia, porcentagem de leitura)\n",
    "leituras = [\n",
    "    (1, 101, 75.0), (1, 102, 50.0), (1, 103, 10.0), (1, 106, 90.0),\n",
    "    (2, 101, 80.0), (2, 104, 90.0), (2, 105, 60.0), (2, 107, 70.0),\n",
    "    (3, 102, 70.0), (3, 103, 40.0), (3, 105, 20.0), (3, 108, 85.0),\n",
    "    (4, 101, 50.0), (4, 106, 95.0), (4, 107, 65.0), (4, 108, 75.0),\n",
    "    (5, 103, 90.0), (5, 104, 80.0), (5, 105, 70.0), (5, 109, 60.0)\n",
    "]\n",
    "\n",
    "# Simulação de dados de notícias (id, tema, data de publicação)\n",
    "noticias = {\n",
    "    101: (\"Crime e Justiça\", \"2025-02-20\"),\n",
    "    102: (\"Economia\", \"2025-02-18\"),\n",
    "    103: (\"Política\", \"2025-02-17\"),\n",
    "    104: (\"Crime e Justiça\", \"2025-02-22\"),\n",
    "    105: (\"Tecnologia\", \"2025-02-15\"),\n",
    "    106: (\"Saúde\", \"2025-02-21\"),\n",
    "    107: (\"Educação\", \"2025-02-19\"),\n",
    "    108: (\"Esportes\", \"2025-02-23\"),\n",
    "    109: (\"Música\", \"2025-02-16\")\n",
    "}\n",
    "\n",
    "# Criando mapeamento de índices\n",
    "usuarios = list(set(l[0] for l in leituras))\n",
    "noticias_ids = list(noticias.keys())\n",
    "user_map = {u: i for i, u in enumerate(usuarios)}\n",
    "noticia_map = {n: i for i, n in enumerate(noticias_ids)}\n",
    "\n",
    "# Criando a matriz de interações\n",
    "num_users = len(usuarios)\n",
    "num_noticias = len(noticias_ids)\n",
    "matriz_interacoes = np.zeros((num_users, num_noticias))\n",
    "for u, n, s in leituras:\n",
    "    matriz_interacoes[user_map[u], noticia_map[n]] = s / 100\n",
    "\n",
    "# Treinando o modelo NMF\n",
    "def train_model(matriz_interacoes):\n",
    "    model = NMF(n_components=5, init='random', random_state=42)\n",
    "    W = model.fit_transform(matriz_interacoes)\n",
    "    H = model.components_\n",
    "    \n",
    "    with open(\"nmf_model5.pkl\", \"wb\") as f:\n",
    "        pickle.dump((model, W, H), f)\n",
    "    return model, W, H\n",
    "\n",
    "# Carregar modelo salvo ou treinar um novo\n",
    "try:\n",
    "    with open(\"nmf_model5.pkl\", \"rb\") as f:\n",
    "        model, W, H = pickle.load(f)\n",
    "    print(\"Modelo carregado com sucesso.\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Modelo não encontrado. Treinando um novo...\")\n",
    "    model, W, H = train_model(matriz_interacoes)\n",
    "\n",
    "# Função para adicionar um novo usuário\n",
    "def add_user(user_id):\n",
    "    if user_id not in user_map:\n",
    "        user_map[user_id] = len(user_map)\n",
    "        global num_users, matriz_interacoes, W\n",
    "        num_users += 1\n",
    "        matriz_interacoes = np.vstack([matriz_interacoes, np.zeros((1, num_noticias))])\n",
    "        W = np.vstack([W, np.zeros((1, W.shape[1]))])\n",
    "        print(f\"Usuário {user_id} adicionado com sucesso.\")\n",
    "    else:\n",
    "        print(f\"Usuário {user_id} já existe.\")\n",
    "\n",
    "# Função para adicionar uma nova notícia\n",
    "def add_news(noticia_id, tema, data_publicacao):\n",
    "    if noticia_id not in noticias:\n",
    "        noticias[noticia_id] = (tema, data_publicacao)\n",
    "        global num_noticias, matriz_interacoes, H, noticias_ids\n",
    "        num_noticias += 1\n",
    "        matriz_interacoes = np.hstack([matriz_interacoes, np.zeros((num_users, 1))])\n",
    "        H = np.hstack([H, np.zeros((H.shape[0], 1))])  # Corrigindo a expansão de H\n",
    "        noticias_ids.append(noticia_id)  # Atualizando a lista de notícias\n",
    "        print(f\"Notícia {noticia_id} adicionada com sucesso.\")\n",
    "    else:\n",
    "        print(f\"Notícia {noticia_id} já existe.\")\n",
    "\n",
    "# Função para recomendar notícias\n",
    "def recommend_news(user_id, n=3):\n",
    "    if user_id not in user_map:\n",
    "        return recommend_popular_news(n)\n",
    "    \n",
    "    user_idx = user_map[user_id]\n",
    "    scores = np.dot(W[user_idx], H)\n",
    "    ranked_news_idx = np.argsort(scores)[::-1]\n",
    "    \n",
    "    temas_interacoes = {}\n",
    "    for idx in ranked_news_idx:\n",
    "        noticia_id = noticias_ids[idx]\n",
    "        tema, data_pub = noticias[noticia_id]\n",
    "        if tema not in temas_interacoes:\n",
    "            temas_interacoes[tema] = []\n",
    "        temas_interacoes[tema].append((noticia_id, datetime.strptime(data_pub, \"%Y-%m-%d\")))\n",
    "    \n",
    "    melhor_tema = max(temas_interacoes, key=lambda t: len(temas_interacoes[t]))\n",
    "    noticias_relevantes = sorted(temas_interacoes[melhor_tema], key=lambda x: x[1], reverse=True)[:n]\n",
    "    \n",
    "    return [noticia_id for noticia_id, _ in noticias_relevantes]\n",
    "\n",
    "# Função para verificar recomendação de nova notícia\n",
    "def check_new_news_recommendation(user_id, noticia_id):\n",
    "    if user_id not in user_map:\n",
    "        print(\"Usuário não encontrado.\")\n",
    "        return\n",
    "    \n",
    "    user_recommendations = recommend_news(user_id, n=5)\n",
    "    if noticia_id in user_recommendations:\n",
    "        print(f\"A nova notícia {noticia_id} foi recomendada para o usuário {user_id}!\")\n",
    "    else:\n",
    "        print(f\"A nova notícia {noticia_id} NÃO foi recomendada para o usuário {user_id}.\")\n",
    "\n",
    "# Exemplo de adição de novo usuário e recomendação\n",
    "new_user_id = 99\n",
    "add_user(new_user_id)\n",
    "recommended_news_new_user = recommend_news(new_user_id)\n",
    "print(f\"Notícias recomendadas para o novo usuário {new_user_id}: {recommended_news_new_user}\")\n",
    "\n",
    "# Exemplo de adição de nova notícia\n",
    "new_noticia_id = 110\n",
    "add_news(new_noticia_id, \"Ciência\", \"2025-02-24\")\n",
    "\n",
    "# Verificando se a nova notícia será recomendada\n",
    "check_new_news_recommendation(1, new_noticia_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "e4fb9b66-468e-4829-aca6-7abaf8db60e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo carregado com sucesso.\n",
      "Usuário 99 adicionado com sucesso.\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[107], line 142\u001b[0m\n\u001b[0;32m    140\u001b[0m new_user_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m99\u001b[39m\n\u001b[0;32m    141\u001b[0m add_user(new_user_id)\n\u001b[1;32m--> 142\u001b[0m recommended_news_new_user \u001b[38;5;241m=\u001b[39m recommend_news(new_user_id)\n\u001b[0;32m    143\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNotícias recomendadas para o novo usuário \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnew_user_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrecommended_news_new_user\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    145\u001b[0m \u001b[38;5;66;03m# Exemplo de adição de nova notícia\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[107], line 105\u001b[0m, in \u001b[0;36mrecommend_news\u001b[1;34m(user_id, n)\u001b[0m\n\u001b[0;32m    103\u001b[0m temas_interacoes \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    104\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m ranked_news_idx:\n\u001b[1;32m--> 105\u001b[0m     noticia_id \u001b[38;5;241m=\u001b[39m noticias_ids[idx]\n\u001b[0;32m    106\u001b[0m     tema, data_pub \u001b[38;5;241m=\u001b[39m noticias[noticia_id]\n\u001b[0;32m    107\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m tema \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m temas_interacoes:\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import sqlite3\n",
    "import pickle\n",
    "from sklearn.decomposition import NMF\n",
    "from scipy.sparse import csr_matrix\n",
    "from datetime import datetime\n",
    "\n",
    "# Simulação de dados de interações (usuário, notícia, porcentagem de leitura)\n",
    "leituras = [\n",
    "    (1, 110, 75.0), (1, 111, 95.0), (1, 103, 10.0), (1, 112, 90.0),\n",
    "    (2, 101, 80.0), (2, 104, 90.0), (2, 105, 60.0), (2, 107, 70.0),\n",
    "    (3, 102, 70.0), (3, 103, 40.0), (3, 105, 20.0), (3, 108, 85.0),\n",
    "    (4, 101, 50.0), (4, 106, 100.0), (4, 107, 65.0), (4, 108, 75.0),\n",
    "    (5, 103, 90.0), (5, 106, 100.0), (5, 105, 70.0), (5, 109, 60.0)\n",
    "]\n",
    "\n",
    "# Simulação de dados de notícias (id, tema, data de publicação)\n",
    "noticias = {\n",
    "    101: (\"Crime e Justiça\", \"2025-02-20\"),\n",
    "    102: (\"Economia\", \"2025-02-18\"),\n",
    "    103: (\"Política\", \"2025-02-17\"),\n",
    "    104: (\"Crime e Justiça\", \"2025-02-22\"),\n",
    "    105: (\"Tecnologia\", \"2025-02-15\"),\n",
    "    106: (\"Saúde\", \"2025-02-21\"),\n",
    "    107: (\"Educação\", \"2025-02-19\"),\n",
    "    108: (\"Esportes\", \"2025-02-23\"),\n",
    "    109: (\"Música\", \"2025-02-16\"),\n",
    "    110: (\"Ciência\", \"2025-02-19\"),\n",
    "    111: (\"Ciência\", \"2025-02-18\"),\n",
    "    112: (\"Ciência\", \"2025-02-17\"),\n",
    "    113: (\"Ciência\", \"2025-02-20\"),\n",
    "}\n",
    "\n",
    "# Criando mapeamento de índices\n",
    "usuarios = list(set(l[0] for l in leituras))\n",
    "noticias_ids = list(noticias.keys())\n",
    "user_map = {u: i for i, u in enumerate(usuarios)}\n",
    "noticia_map = {n: i for i, n in enumerate(noticias_ids)}\n",
    "\n",
    "# Criando a matriz de interações\n",
    "num_users = len(usuarios)\n",
    "num_noticias = len(noticias_ids)\n",
    "matriz_interacoes = np.zeros((num_users, num_noticias))\n",
    "for u, n, s in leituras:\n",
    "    matriz_interacoes[user_map[u], noticia_map[n]] = s / 100\n",
    "\n",
    "# Treinando o modelo NMF\n",
    "def train_model(matriz_interacoes):\n",
    "    model = NMF(n_components=5, init='random', random_state=42)\n",
    "    W = model.fit_transform(matriz_interacoes)\n",
    "    H = model.components_\n",
    "    \n",
    "    with open(\"nmf_model10.pkl\", \"wb\") as f:\n",
    "        pickle.dump((model, W, H), f)\n",
    "    return model, W, H\n",
    "\n",
    "# Carregar modelo salvo ou treinar um novo\n",
    "try:\n",
    "    with open(\"nmf_model10.pkl\", \"rb\") as f:\n",
    "        model, W, H = pickle.load(f)\n",
    "    print(\"Modelo carregado com sucesso.\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Modelo não encontrado. Treinando um novo...\")\n",
    "    model, W, H = train_model(matriz_interacoes)\n",
    "\n",
    "# Função para adicionar um novo usuário\n",
    "def add_user(user_id):\n",
    "    if user_id not in user_map:\n",
    "        user_map[user_id] = len(user_map)\n",
    "        global num_users, matriz_interacoes, W\n",
    "        num_users += 1\n",
    "        matriz_interacoes = np.vstack([matriz_interacoes, np.zeros((1, num_noticias))])\n",
    "        W = np.vstack([W, np.zeros((1, W.shape[1]))])\n",
    "        print(f\"Usuário {user_id} adicionado com sucesso.\")\n",
    "    else:\n",
    "        print(f\"Usuário {user_id} já existe.\")\n",
    "\n",
    "# Função para adicionar uma nova notícia\n",
    "def add_news(noticia_id, tema, data_publicacao):\n",
    "    if noticia_id not in noticias:\n",
    "        noticias[noticia_id] = (tema, data_publicacao)\n",
    "        global num_noticias, matriz_interacoes, H, noticias_ids\n",
    "        num_noticias += 1\n",
    "        matriz_interacoes = np.hstack([matriz_interacoes, np.zeros((num_users, 1))])\n",
    "        H = np.hstack([H, np.zeros((H.shape[0], 1))])  # Corrigindo a expansão de H\n",
    "        noticias_ids.append(noticia_id)  # Atualizando a lista de notícias\n",
    "        print(f\"Notícia {noticia_id} adicionada com sucesso.\")\n",
    "        # Re-treinar o modelo após adicionar a notícia\n",
    "        global model, W\n",
    "        model, W, H = train_model(matriz_interacoes)\n",
    "    else:\n",
    "        print(f\"Notícia {noticia_id} já existe.\")\n",
    "\n",
    "# Função para recomendar notícias\n",
    "def recommend_news(user_id, n=3):\n",
    "    if user_id not in user_map:\n",
    "        return recommend_popular_news(n)\n",
    "    \n",
    "    user_idx = user_map[user_id]\n",
    "    scores = np.dot(W[user_idx], H)\n",
    "    ranked_news_idx = np.argsort(scores)[::-1]\n",
    "    \n",
    "    temas_interacoes = {}\n",
    "    for idx in ranked_news_idx:\n",
    "        noticia_id = noticias_ids[idx]\n",
    "        tema, data_pub = noticias[noticia_id]\n",
    "        if tema not in temas_interacoes:\n",
    "            temas_interacoes[tema] = []\n",
    "        temas_interacoes[tema].append((noticia_id, datetime.strptime(data_pub, \"%Y-%m-%d\")))\n",
    "    \n",
    "    melhor_tema = max(temas_interacoes, key=lambda t: len(temas_interacoes[t]))\n",
    "    noticias_relevantes = sorted(temas_interacoes[melhor_tema], key=lambda x: x[1], reverse=True)[:n]\n",
    "    \n",
    "    return [noticia_id for noticia_id, _ in noticias_relevantes]\n",
    "\n",
    "# Função para verificar recomendação de nova notícia\n",
    "def check_new_news_recommendation(user_id, noticia_id):\n",
    "    if user_id not in user_map:\n",
    "        print(\"Usuário não encontrado.\")\n",
    "        return\n",
    "    \n",
    "    user_recommendations = recommend_news(user_id, n=5)\n",
    "    if noticia_id in user_recommendations:\n",
    "        print(f\"A nova notícia {noticia_id} foi recomendada para o usuário {user_id}!\")\n",
    "    else:\n",
    "        print(f\"A nova notícia {noticia_id} NÃO foi recomendada para o usuário {user_id}.\")\n",
    "\n",
    "# Função para recomendar notícias populares\n",
    "def recommend_popular_news(n=3):\n",
    "    popularity = {}\n",
    "    for u, noticia_id, score in leituras:\n",
    "        if noticia_id not in popularity:\n",
    "            popularity[noticia_id] = 0\n",
    "        popularity[noticia_id] += score\n",
    "    \n",
    "    popular_news = sorted(popularity, key=popularity.get, reverse=True)[:n]\n",
    "    return popular_news\n",
    "\n",
    "# Exemplo de adição de novo usuário e recomendação\n",
    "new_user_id = 99\n",
    "add_user(new_user_id)\n",
    "recommended_news_new_user = recommend_news(new_user_id)\n",
    "print(f\"Notícias recomendadas para o novo usuário {new_user_id}: {recommended_news_new_user}\")\n",
    "\n",
    "# Exemplo de adição de nova notícia\n",
    "new_noticia_id = 114\n",
    "add_news(new_noticia_id, \"Ciência\", \"2025-02-24\")\n",
    "\n",
    "# Verificando se a nova notícia será recomendada\n",
    "check_new_news_recommendation(1, new_noticia_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "b38409cd-5fc0-4f59-bb2c-aec87e9c7b48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo carregado com sucesso.\n",
      "[110, 111, 112, 113]\n",
      "A nova notícia 114 NÃO foi recomendada para o usuário 1.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import sqlite3\n",
    "import pickle\n",
    "from sklearn.decomposition import NMF\n",
    "from scipy.sparse import csr_matrix\n",
    "from datetime import datetime\n",
    "\n",
    "# Simulação de dados de interações (usuário, notícia, porcentagem de leitura)\n",
    "leituras = [\n",
    "    (1, 110, 75.0), (1, 111, 95.0), (1, 103, 10.0), (1, 112, 90.0),\n",
    "    (2, 101, 80.0), (2, 104, 90.0), (2, 105, 60.0), (2, 107, 70.0),\n",
    "    (3, 102, 70.0), (3, 103, 40.0), (3, 105, 20.0), (3, 108, 85.0),\n",
    "    (4, 101, 50.0), (4, 106, 100.0), (4, 107, 65.0), (4, 108, 75.0),\n",
    "    (5, 103, 90.0), (5, 106, 100.0), (5, 105, 70.0), (5, 109, 60.0)\n",
    "]\n",
    "\n",
    "# Simulação de dados de notícias (id, tema, data de publicação)\n",
    "noticias = {\n",
    "    101: (\"Crime e Justiça\", \"2025-02-20\"),\n",
    "    102: (\"Economia\", \"2025-02-18\"),\n",
    "    103: (\"Política\", \"2025-02-17\"),\n",
    "    104: (\"Crime e Justiça\", \"2025-02-22\"),\n",
    "    105: (\"Tecnologia\", \"2025-02-15\"),\n",
    "    106: (\"Saúde\", \"2025-02-21\"),\n",
    "    107: (\"Educação\", \"2025-02-19\"),\n",
    "    108: (\"Esportes\", \"2025-02-23\"),\n",
    "    109: (\"Música\", \"2025-02-16\"),\n",
    "    110: (\"Ciência\", \"2025-02-23\"),\n",
    "    111: (\"Ciência\", \"2025-02-22\"),\n",
    "    112: (\"Ciência\", \"2025-02-21\"),\n",
    "    113: (\"Ciência\", \"2025-02-20\"),\n",
    "}\n",
    "\n",
    "# Criando mapeamento de índices\n",
    "usuarios = list(set(l[0] for l in leituras))\n",
    "noticias_ids = list(noticias.keys())\n",
    "user_map = {u: i for i, u in enumerate(usuarios)}\n",
    "noticia_map = {n: i for i, n in enumerate(noticias_ids)}\n",
    "\n",
    "# Criando a matriz de interações\n",
    "num_users = len(usuarios)\n",
    "num_noticias = len(noticias_ids)\n",
    "matriz_interacoes = np.zeros((num_users, num_noticias))\n",
    "for u, n, s in leituras:\n",
    "    matriz_interacoes[user_map[u], noticia_map[n]] = s / 100\n",
    "\n",
    "# Treinando o modelo NMF\n",
    "def train_model(matriz_interacoes):\n",
    "    model = NMF(n_components=5, init='random', random_state=42)\n",
    "    W = model.fit_transform(matriz_interacoes)\n",
    "    H = model.components_\n",
    "    \n",
    "    with open(\"nmf_model.pkl\", \"wb\") as f:\n",
    "        pickle.dump((model, W, H), f)\n",
    "    return model, W, H\n",
    "\n",
    "# Carregar modelo salvo ou treinar um novo\n",
    "try:\n",
    "    with open(\"nmf_model.pkl\", \"rb\") as f:\n",
    "        model, W, H = pickle.load(f)\n",
    "    print(\"Modelo carregado com sucesso.\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Modelo não encontrado. Treinando um novo...\")\n",
    "    model, W, H = train_model(matriz_interacoes)\n",
    "\n",
    "# Função para adicionar um novo usuário\n",
    "def add_user(user_id):\n",
    "    if user_id not in user_map:\n",
    "        user_map[user_id] = len(user_map)\n",
    "        global num_users, matriz_interacoes, W\n",
    "        num_users += 1\n",
    "        matriz_interacoes = np.vstack([matriz_interacoes, np.zeros((1, num_noticias))])\n",
    "        W = np.vstack([W, np.zeros((1, W.shape[1]))])\n",
    "        print(f\"Usuário {user_id} adicionado com sucesso.\")\n",
    "    else:\n",
    "        print(f\"Usuário {user_id} já existe.\")\n",
    "\n",
    "# Função para adicionar uma nova notícia\n",
    "def add_news(noticia_id, tema, data_publicacao):\n",
    "    if noticia_id not in noticias:\n",
    "        noticias[noticia_id] = (tema, data_publicacao)\n",
    "        global num_noticias, matriz_interacoes, H, noticias_ids\n",
    "        num_noticias += 1\n",
    "        matriz_interacoes = np.hstack([matriz_interacoes, np.zeros((num_users, 1))])\n",
    "        H = np.hstack([H, np.zeros((H.shape[0], 1))])\n",
    "        noticias_ids.append(noticia_id)\n",
    "        print(f\"Notícia {noticia_id} adicionada com sucesso.\")\n",
    "        global model, W\n",
    "        model, W, H = train_model(matriz_interacoes)\n",
    "    else:\n",
    "        print(f\"Notícia {noticia_id} já existe.\")\n",
    "\n",
    "# Função para recomendar notícias populares\n",
    "def recommend_popular_news(n=3):\n",
    "    popularity = {}\n",
    "    count_reads = {}\n",
    "    for _, noticia_id, score in leituras:\n",
    "        if noticia_id not in popularity:\n",
    "            popularity[noticia_id] = 0\n",
    "            count_reads[noticia_id] = 0\n",
    "        popularity[noticia_id] += score\n",
    "        count_reads[noticia_id] += 1\n",
    "    \n",
    "    weighted_popularity = {news_id: popularity[news_id] * count_reads[news_id] for news_id in popularity}\n",
    "    popular_news = sorted(weighted_popularity.items(), key=lambda x: x[1], reverse=True)\n",
    "    return [news_id for news_id, _ in popular_news[:n]]\n",
    "\n",
    "# Função para recomendar notícias\n",
    "def recommend_news(user_id, n=3):\n",
    "    if user_id not in user_map:\n",
    "        return recommend_popular_news(n)\n",
    "    \n",
    "    user_idx = user_map[user_id]\n",
    "    scores = np.dot(W[user_idx], H)\n",
    "    ranked_news_idx = np.argsort(scores)[::-1]\n",
    "    \n",
    "    temas_interacoes = {}\n",
    "    for idx in ranked_news_idx:\n",
    "        noticia_id = noticias_ids[idx]\n",
    "        tema, data_pub = noticias[noticia_id]\n",
    "        if tema not in temas_interacoes:\n",
    "            temas_interacoes[tema] = []\n",
    "        temas_interacoes[tema].append((noticia_id, datetime.strptime(data_pub, \"%Y-%m-%d\")))\n",
    "    \n",
    "    melhor_tema = max(temas_interacoes, key=lambda t: len(temas_interacoes[t]))\n",
    "    noticias_relevantes = sorted(temas_interacoes[melhor_tema], key=lambda x: x[1], reverse=True)[:n]\n",
    "    \n",
    "    return [noticia_id for noticia_id, _ in noticias_relevantes]\n",
    "\n",
    "# Função para verificar recomendação de nova notícia\n",
    "def check_new_news_recommendation(user_id, noticia_id):\n",
    "    if user_id not in user_map:\n",
    "        print(\"Usuário não encontrado.\")\n",
    "        return\n",
    "    \n",
    "    user_recommendations = recommend_news(user_id, n=5)\n",
    "    print(user_recommendations)\n",
    "    if noticia_id in user_recommendations:\n",
    "        print(f\"A nova notícia {noticia_id} foi recomendada para o usuário {user_id}!\")\n",
    "    else:\n",
    "        print(f\"A nova notícia {noticia_id} NÃO foi recomendada para o usuário {user_id}.\")\n",
    "\n",
    "\n",
    "# Exemplo de adição de novo usuário e recomendação\n",
    "# new_user_id = 99\n",
    "# add_user(new_user_id)\n",
    "# recommended_news_new_user = recommend_news(new_user_id)\n",
    "# print(f\"Notícias recomendadas para o novo usuário {new_user_id}: {recommended_news_new_user}\")\n",
    "\n",
    "# # Exemplo de adição de nova notícia\n",
    "# new_noticia_id = 114\n",
    "# add_news(new_noticia_id, \"Ciência\", \"2025-02-24\")\n",
    "\n",
    "# Verificando se a nova notícia será recomendada\n",
    "check_new_news_recommendation(1, new_noticia_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "4ea14a61-785c-48a8-b1ba-c76b5594e636",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo carregado com sucesso.\n",
      "Notícia 114 adicionada com sucesso.\n",
      "A nova notícia 114 NÃO foi recomendada para o usuário 1.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import sqlite3\n",
    "import pickle\n",
    "from sklearn.decomposition import NMF\n",
    "from scipy.sparse import csr_matrix\n",
    "from datetime import datetime\n",
    "\n",
    "# Simulação de dados de interações (usuário, notícia, porcentagem de leitura)\n",
    "leituras = [\n",
    "    (1, 110, 75.0), (1, 111, 95.0), (1, 103, 10.0), (1, 112, 90.0),\n",
    "    (2, 101, 80.0), (2, 104, 90.0), (2, 105, 60.0), (2, 107, 70.0),\n",
    "    (3, 102, 70.0), (3, 103, 40.0), (3, 105, 20.0), (3, 108, 85.0),\n",
    "    (4, 101, 50.0), (4, 106, 100.0), (4, 107, 65.0), (4, 108, 75.0),\n",
    "    (5, 103, 90.0), (5, 106, 100.0), (5, 105, 70.0), (5, 109, 60.0)\n",
    "]\n",
    "\n",
    "# Simulação de dados de notícias (id, tema, data de publicação)\n",
    "noticias = {\n",
    "    101: (\"Crime e Justiça\", \"2025-02-20\"),\n",
    "    102: (\"Economia\", \"2025-02-18\"),\n",
    "    103: (\"Política\", \"2025-02-17\"),\n",
    "    104: (\"Crime e Justiça\", \"2025-02-22\"),\n",
    "    105: (\"Tecnologia\", \"2025-02-15\"),\n",
    "    106: (\"Saúde\", \"2025-02-21\"),\n",
    "    107: (\"Educação\", \"2025-02-19\"),\n",
    "    108: (\"Esportes\", \"2025-02-23\"),\n",
    "    109: (\"Música\", \"2025-02-16\"),\n",
    "    110: (\"Ciência\", \"2025-02-23\"),\n",
    "    111: (\"Ciência\", \"2025-02-22\"),\n",
    "    112: (\"Ciência\", \"2025-02-21\"),\n",
    "    113: (\"Ciência\", \"2025-02-20\"),\n",
    "}\n",
    "\n",
    "# Criando mapeamento de índices\n",
    "usuarios = list(set(l[0] for l in leituras))\n",
    "noticias_ids = list(noticias.keys())\n",
    "user_map = {u: i for i, u in enumerate(usuarios)}\n",
    "noticia_map = {n: i for i, n in enumerate(noticias_ids)}\n",
    "\n",
    "# Criando a matriz de interações\n",
    "num_users = len(usuarios)\n",
    "num_noticias = len(noticias_ids)\n",
    "matriz_interacoes = np.zeros((num_users, num_noticias))\n",
    "for u, n, s in leituras:\n",
    "    matriz_interacoes[user_map[u], noticia_map[n]] = s / 100\n",
    "\n",
    "# Treinando o modelo NMF\n",
    "def train_model(matriz_interacoes):\n",
    "    model = NMF(n_components=5, init='random', random_state=42)\n",
    "    W = model.fit_transform(matriz_interacoes)\n",
    "    H = model.components_\n",
    "    \n",
    "    with open(\"nmf_model.pkl\", \"wb\") as f:\n",
    "        pickle.dump((model, W, H), f)\n",
    "    return model, W, H\n",
    "\n",
    "# Carregar modelo salvo ou treinar um novo\n",
    "try:\n",
    "    with open(\"nmf_model.pkl\", \"rb\") as f:\n",
    "        model, W, H = pickle.load(f)\n",
    "    print(\"Modelo carregado com sucesso.\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Modelo não encontrado. Treinando um novo...\")\n",
    "    model, W, H = train_model(matriz_interacoes)\n",
    "\n",
    "# Função para adicionar um novo usuário\n",
    "def add_user(user_id):\n",
    "    if user_id not in user_map:\n",
    "        user_map[user_id] = len(user_map)\n",
    "        global num_users, matriz_interacoes, W\n",
    "        num_users += 1\n",
    "        matriz_interacoes = np.vstack([matriz_interacoes, np.zeros((1, num_noticias))])\n",
    "        W = np.vstack([W, np.zeros((1, W.shape[1]))])\n",
    "        print(f\"Usuário {user_id} adicionado com sucesso.\")\n",
    "    else:\n",
    "        print(f\"Usuário {user_id} já existe.\")\n",
    "\n",
    "# Função para adicionar uma nova notícia\n",
    "def add_news(noticia_id, tema, data_publicacao):\n",
    "    if noticia_id not in noticias:\n",
    "        noticias[noticia_id] = (tema, data_publicacao)\n",
    "        global num_noticias, matriz_interacoes, H, noticias_ids\n",
    "        num_noticias += 1\n",
    "        matriz_interacoes = np.hstack([matriz_interacoes, np.zeros((num_users, 1))])\n",
    "        H = np.hstack([H, np.zeros((H.shape[0], 1))])\n",
    "        noticias_ids.append(noticia_id)\n",
    "        print(f\"Notícia {noticia_id} adicionada com sucesso.\")\n",
    "        global model, W\n",
    "        model, W, H = train_model(matriz_interacoes)\n",
    "    else:\n",
    "        print(f\"Notícia {noticia_id} já existe.\")\n",
    "\n",
    "# Função para recomendar notícias populares\n",
    "def recommend_popular_news(n=3):\n",
    "    popularity = {}\n",
    "    count_reads = {}\n",
    "    for user_id, noticia_id, score in leituras:\n",
    "        if score > 50.0:\n",
    "            continue\n",
    "        if noticia_id not in popularity:\n",
    "            popularity[noticia_id] = 0\n",
    "            count_reads[noticia_id] = 0\n",
    "        popularity[noticia_id] += score\n",
    "        count_reads[noticia_id] += 1\n",
    "    \n",
    "    weighted_popularity = {news_id: popularity[news_id] * count_reads[news_id] for news_id in popularity}\n",
    "    popular_news = sorted(weighted_popularity.items(), key=lambda x: x[1], reverse=True)\n",
    "    return [news_id for news_id, _ in popular_news[:n]]\n",
    "\n",
    "# Função para recomendar notícias\n",
    "def recommend_news(user_id, n=3):\n",
    "    if user_id not in user_map:\n",
    "        return recommend_popular_news(n)\n",
    "    \n",
    "    user_idx = user_map[user_id]\n",
    "    scores = np.dot(W[user_idx], H)\n",
    "    ranked_news_idx = np.argsort(scores)[::-1]\n",
    "    \n",
    "    recomendadas = []\n",
    "    for idx in ranked_news_idx:\n",
    "        noticia_id = noticias_ids[idx]\n",
    "        if any(u == user_id and n == noticia_id and s > 50.0 for u, n, s in leituras):\n",
    "            continue\n",
    "        recomendadas.append(noticia_id)\n",
    "        if len(recomendadas) >= n:\n",
    "            break\n",
    "    \n",
    "    return recomendadas\n",
    "\n",
    "\n",
    "# Exemplo de adição de novo usuário e recomendação\n",
    "# new_user_id = 99\n",
    "# add_user(new_user_id)\n",
    "# recommended_news_new_user = recommend_news(new_user_id)\n",
    "# print(f\"Notícias recomendadas para o novo usuário {new_user_id}: {recommended_news_new_user}\")\n",
    "\n",
    "# # Exemplo de adição de nova notícia\n",
    "new_noticia_id = 114\n",
    "add_news(new_noticia_id, \"Ciência\", \"2025-02-24\")\n",
    "\n",
    "# Verificando se a nova notícia será recomendada\n",
    "check_new_news_recommendation(1, new_noticia_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "965242d7-e48c-4d4d-961e-cbee10294222",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_id=1\n",
    "user_idx = user_map[user_id]\n",
    "scores = np.dot(W[user_idx], H)\n",
    "ranked_news_idx = np.argsort(scores)[::-1]\n",
    "recomendadas = []\n",
    "for idx in ranked_news_idx:\n",
    "    noticia_id = noticias_ids[idx]\n",
    "    if any(u == user_id and n == noticia_id and s > 50.0 for u, n, s in leituras):\n",
    "        continue\n",
    "    recomendadas.append(noticia_id)\n",
    "    if len(recomendadas) >= n:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "68bd89ff-b02e-439b-8cd9-a33014c73d68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114]"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noticias_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "83003d67-0faa-4e77-8671-fb3d9734c2b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([10, 11,  9,  2,  7,  1,  4,  3, 13, 12,  8,  6,  5,  0],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ranked_news_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "c136acc1-96c5-4232-bb71-0a5eb01cb537",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[103, 108, 102, 105, 104, 114, 113, 109, 107, 106, 101]"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recomendadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "7f416217-66a0-4bc2-9a2b-1db5e2dafb34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 110, 75.0),\n",
       " (1, 111, 95.0),\n",
       " (1, 103, 10.0),\n",
       " (1, 112, 90.0),\n",
       " (2, 101, 80.0),\n",
       " (2, 104, 90.0),\n",
       " (2, 105, 60.0),\n",
       " (2, 107, 70.0),\n",
       " (3, 102, 70.0),\n",
       " (3, 103, 40.0),\n",
       " (3, 105, 20.0),\n",
       " (3, 108, 85.0),\n",
       " (4, 101, 50.0),\n",
       " (4, 106, 100.0),\n",
       " (4, 107, 65.0),\n",
       " (4, 108, 75.0),\n",
       " (5, 103, 90.0),\n",
       " (5, 106, 100.0),\n",
       " (5, 105, 70.0),\n",
       " (5, 109, 60.0)]"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "leituras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c986183-5733-40e3-8297-5f276a6cdd88",
   "metadata": {},
   "source": [
    "📌 Objetivo do Código\n",
    "Este código implementa um sistema de recomendação de notícias utilizando Filtragem Colaborativa com o modelo NMF (Non-Negative Matrix Factorization).\n",
    "\n",
    "Ele recomenda notícias para os usuários com base nas suas interações anteriores (percentual de leitura de cada notícia). Para novos usuários (cold start), ele recomenda as notícias mais populares entre os usuários existentes.\n",
    "\n",
    "🔹 1. Simulação de Dados\n",
    "python\n",
    "Copiar\n",
    "Editar\n",
    "# Simulação de dados de interações (usuário, notícia, porcentagem de leitura)\n",
    "leituras = [\n",
    "    (1, 101, 75.0), (1, 102, 50.0), (1, 103, 10.0),\n",
    "    (2, 101, 80.0), (2, 104, 90.0), (2, 105, 60.0),\n",
    "    (3, 102, 70.0), (3, 103, 40.0), (3, 105, 20.0)\n",
    "]\n",
    "💡 O que são essas interações?\n",
    "\n",
    "Cada tupla representa um usuário que leu uma notícia e qual porcentagem dessa notícia ele consumiu.\n",
    "Por exemplo, (1, 101, 75.0) significa que o usuário 1 leu 75% da notícia 101.\n",
    "python\n",
    "Copiar\n",
    "Editar\n",
    "# Simulação de dados de notícias (id, tema, data de publicação)\n",
    "noticias = {\n",
    "    101: (\"Crime e Justiça\", \"2025-02-20\"),\n",
    "    102: (\"Economia\", \"2025-02-18\"),\n",
    "    103: (\"Política\", \"2025-02-17\"),\n",
    "    104: (\"Crime e Justiça\", \"2025-02-22\"),\n",
    "    105: (\"Tecnologia\", \"2025-02-15\")\n",
    "}\n",
    "💡 O que significa isso?\n",
    "\n",
    "Cada notícia tem um ID, um tema e uma data de publicação.\n",
    "Por exemplo, 101: (\"Crime e Justiça\", \"2025-02-20\") significa que a notícia 101 fala sobre Crime e Justiça e foi publicada em 20 de fevereiro de 2025.\n",
    "🔹 2. Criando a Matriz de Interação\n",
    "Antes de treinar o modelo, transformamos os dados em uma matriz de interações.\n",
    "\n",
    "python\n",
    "Copiar\n",
    "Editar\n",
    "# Criando mapeamento de índices\n",
    "usuarios = list(set(l[0] for l in leituras))\n",
    "noticias_ids = list(set(l[1] for l in leituras))\n",
    "user_map = {u: i for i, u in enumerate(usuarios)}\n",
    "noticia_map = {n: i for i, n in enumerate(noticias_ids)}\n",
    "💡 Por que precisamos disso?\n",
    "\n",
    "Os modelos trabalham melhor com índices numéricos sequenciais ao invés de identificadores arbitrários.\n",
    "user_map e noticia_map transformam IDs de usuários e notícias em índices numéricos.\n",
    "python\n",
    "Copiar\n",
    "Editar\n",
    "# Criando a matriz de interações\n",
    "num_users = len(usuarios)\n",
    "num_noticias = len(noticias_ids)\n",
    "matriz_interacoes = np.zeros((num_users, num_noticias))\n",
    "for u, n, s in leituras:\n",
    "    matriz_interacoes[user_map[u], noticia_map[n]] = s / 100\n",
    "💡 O que isso faz?\n",
    "\n",
    "Criamos uma matriz num_users × num_noticias com zeros.\n",
    "Para cada interação (usuário, notícia, percentual de leitura), preenchemos a matriz com valores entre 0 e 1.\n",
    "Exemplo: Se um usuário leu 75% de uma notícia, armazenamos 0.75 na posição correspondente.\n",
    "🔹 3. Treinando o Modelo NMF\n",
    "Agora treinamos o modelo NMF para encontrar padrões nos dados.\n",
    "\n",
    "python\n",
    "Copiar\n",
    "Editar\n",
    "# Treinando o modelo NMF\n",
    "def train_model(matriz_interacoes):\n",
    "    model = NMF(n_components=5, init='random', random_state=42)\n",
    "    W = model.fit_transform(matriz_interacoes)\n",
    "    H = model.components_\n",
    "    \n",
    "    with open(\"nmf_model.pkl\", \"wb\") as f:\n",
    "        pickle.dump((model, W, H), f)\n",
    "    return model, W, H\n",
    "💡 O que é o NMF?\n",
    "\n",
    "O NMF (Non-Negative Matrix Factorization) decompõe a matriz em dois conjuntos de fatores:\n",
    "W representa os perfis dos usuários.\n",
    "H representa os perfis das notícias.\n",
    "O modelo é salvo no arquivo \"nmf_model.pkl\" para evitar treinar toda vez.\n",
    "🔹 4. Carregar Modelo ou Treinar Novamente\n",
    "python\n",
    "Copiar\n",
    "Editar\n",
    "try:\n",
    "    with open(\"nmf_model.pkl\", \"rb\") as f:\n",
    "        model, W, H = pickle.load(f)\n",
    "    print(\"Modelo carregado com sucesso.\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Modelo não encontrado. Treinando um novo...\")\n",
    "    model, W, H = train_model(matriz_interacoes)\n",
    "💡 Por que carregar o modelo?\n",
    "\n",
    "Para evitar retrainamento desnecessário e economizar tempo.\n",
    "🔹 5. Recomendação de Notícias\n",
    "Agora usamos o modelo para recomendar notícias.\n",
    "\n",
    "python\n",
    "Copiar\n",
    "Editar\n",
    "def recommend_news(user_id, n=3):\n",
    "    if user_id not in user_map:\n",
    "        return recommend_popular_news(n)\n",
    "    \n",
    "    user_idx = user_map[user_id]\n",
    "    scores = np.dot(W[user_idx], H)\n",
    "    ranked_news_idx = np.argsort(scores)[::-1]\n",
    "💡 Como funciona?\n",
    "\n",
    "Se o usuário for novo, ele recebe notícias populares.\n",
    "Se ele já interagiu antes, calculamos um score de preferência multiplicando W[user] × H.\n",
    "As notícias são ordenadas por esse score.\n",
    "python\n",
    "Copiar\n",
    "Editar\n",
    "    temas_interacoes = {}\n",
    "    for idx in ranked_news_idx:\n",
    "        noticia_id = noticias_ids[idx]\n",
    "        tema, data_pub = noticias[noticia_id]\n",
    "        if tema not in temas_interacoes:\n",
    "            temas_interacoes[tema] = []\n",
    "        temas_interacoes[tema].append((noticia_id, datetime.strptime(data_pub, \"%Y-%m-%d\")))\n",
    "    \n",
    "    melhor_tema = max(temas_interacoes, key=lambda t: len(temas_interacoes[t]))\n",
    "    noticias_relevantes = sorted(temas_interacoes[melhor_tema], key=lambda x: x[1], reverse=True)[:n]\n",
    "    \n",
    "    return [noticia_id for noticia_id, _ in noticias_relevantes]\n",
    "💡 Como garantimos que as notícias são recentes?\n",
    "\n",
    "Agrupamos notícias por tema.\n",
    "Escolhemos o tema mais relevante baseado na quantidade de interações.\n",
    "Ordenamos as notícias desse tema pela data de publicação.\n",
    "🔹 6. Recomendação para Novos Usuários\n",
    "python\n",
    "Copiar\n",
    "Editar\n",
    "def recommend_popular_news(n=3):\n",
    "    popularidade = {}\n",
    "    for _, noticia_id, leitura in leituras:\n",
    "        if noticia_id not in popularidade:\n",
    "            popularidade[noticia_id] = []\n",
    "        popularidade[noticia_id].append(leitura)\n",
    "    \n",
    "    media_popularidade = {k: np.mean(v) for k, v in popularidade.items()}\n",
    "    noticias_populares = sorted(media_popularidade.keys(), key=lambda x: (media_popularidade[x], noticias[x][1]), reverse=True)\n",
    "    \n",
    "    return noticias_populares[:n]\n",
    "💡 Como funciona?\n",
    "\n",
    "Calculamos a média de leitura de cada notícia.\n",
    "Ordenamos as notícias pela popularidade e recência.\n",
    "🔹 7. Atualizando e Retreinando o Modelo\n",
    "python\n",
    "Copiar\n",
    "Editar\n",
    "def update_and_retrain(new_lectures):\n",
    "    global leituras, model, W, H, matriz_interacoes\n",
    "    leituras.extend(new_lectures)\n",
    "    matriz_interacoes = np.zeros((num_users, num_noticias))\n",
    "    for u, n, s in leituras:\n",
    "        matriz_interacoes[user_map[u], noticia_map[n]] = s / 100\n",
    "    model, W, H = train_model(matriz_interacoes)\n",
    "    print(\"Modelo atualizado com novas interações e salvo.\")\n",
    "💡 Por que isso é importante?\n",
    "\n",
    "Sempre que novos dados são adicionados, o modelo precisa ser atualizado para aprender novas preferências.\n",
    "Isso cobre tudo! Se tiver dúvidas ou quiser modificar algo, me avise! 🚀\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be576c7e-94d2-46b0-b5aa-949538f4efd9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
