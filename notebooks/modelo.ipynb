{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "453d69e6-0033-4cdc-8b44-0843f55a6d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import unidecode\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c4256e55-b464-4c28-8197-d4abc260a260",
   "metadata": {},
   "outputs": [],
   "source": [
    "itens_url = ['itens/itens/itens-parte1.csv', 'itens/itens/itens-parte2.csv', 'itens/itens/itens-parte3.csv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f8be647d-a1c8-4962-9c7d-baf591853a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "itens = pd.DataFrame({'page':[], 'url':[],\n",
    "                     'issued':[], 'modified':[],\n",
    "                      'title':[], 'body':[],\n",
    "                      'caption':[]\n",
    "                     })\n",
    "\n",
    "for item_url in itens_url:\n",
    "    novos_itens = pd.read_csv(item_url)\n",
    "    itens = pd.concat([itens, novos_itens])\n",
    "\n",
    "# novos_itens = pd.read_csv(itens_url[0])\n",
    "# itens = pd.concat([itens, novos_itens])\n",
    "\n",
    "itens['issued'] = pd.to_datetime(itens['issued'])\n",
    "itens['modified'] = pd.to_datetime(itens['modified'])\n",
    "\n",
    "itens['title'] = itens['title'].apply(lambda x: unidecode.unidecode(x.lower()))\n",
    "itens['body'] = itens['body'].apply(lambda x: unidecode.unidecode(x.lower()))\n",
    "itens['caption'] = itens['body'].apply(lambda x: unidecode.unidecode(x.lower()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d820eddf-c3f3-4ce1-8243-2ba45c90faff",
   "metadata": {},
   "outputs": [],
   "source": [
    "del novos_itens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4755a13b-4cd6-4911-b381-a873b5db1217",
   "metadata": {},
   "outputs": [],
   "source": [
    "itens = itens[['page', 'title', 'issued']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8dd0d17-4e74-49d4-a45d-472d815317a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "users_url = ['files/treino/treino_parte1.csv', 'files/treino/treino_parte2.csv', 'files/treino/treino_parte3.csv', 'files/treino/treino_parte4.csv', 'files/treino/treino_parte5.csv', 'files/treino/treino_parte6.csv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e9ab044e-f248-465c-ae96-c7ced50e7f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_user = pd.DataFrame({'userId':[], 'userType':[],\n",
    "                        'historySize':[], 'history':[],\n",
    "                        'timestampHistory':[], 'numberOfClicksHistory':[],\n",
    "                        'timeOnPageHistory':[], 'scrollPercentageHistory':[],\n",
    "                        'pageVisitsCountHistory':[], 'timestampHistory_new':[],       \n",
    "                     })\n",
    "\n",
    "# for user_url in users_url:\n",
    "    # novos_user = pd.read_csv(user_url)\n",
    "    # df_user = pd.concat([df_user, novos_user])\n",
    "\n",
    "novos_user = pd.read_csv(users_url[0])\n",
    "df_user = pd.concat([df_user, novos_user])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f07c43ef-b233-453a-9388-66bdd283f58e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_list(lista, tipo):\n",
    "    retorno = []\n",
    "    if tipo=='int':\n",
    "        for item in lista:\n",
    "            retorno.append(int(item))\n",
    "    else:\n",
    "        for item in lista:\n",
    "            retorno.append(float(item))\n",
    "    return retorno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7c954274-4645-409c-a743-228b5e8bffe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_user['history'] = df_user['history'].str.split(',')\n",
    "df_user['timestampHistory'] = df_user['timestampHistory'].str.split(',')\n",
    "df_user['numberOfClicksHistory'] = df_user['numberOfClicksHistory'].str.split(',')\n",
    "df_user['timeOnPageHistory'] = df_user['timeOnPageHistory'].str.split(',')\n",
    "df_user['scrollPercentageHistory'] = df_user['scrollPercentageHistory'].str.split(',')\n",
    "df_user['pageVisitsCountHistory'] = df_user['pageVisitsCountHistory'].str.split(',')\n",
    "df_user['timestampHistory_new'] = df_user['timestampHistory_new'].str.split(',')\n",
    "\n",
    "df_user['numberOfClicksHistory'] = df_user['numberOfClicksHistory'].apply(lambda x: convert_list(x,'int'))\n",
    "df_user['timeOnPageHistory'] = df_user['timeOnPageHistory'].apply(lambda x: convert_list(x,'int'))\n",
    "df_user['scrollPercentageHistory'] = df_user['scrollPercentageHistory'].apply(lambda x: convert_list(x,'float'))\n",
    "df_user['pageVisitsCountHistory'] = df_user['pageVisitsCountHistory'].apply(lambda x: convert_list(x,'int'))\n",
    "df_user['scrollPercentageHistory'] = df_user['scrollPercentageHistory'].apply(lambda lst: [np.where(x > 100, 100, x) for x in lst])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1f5a8bc5-3e7c-4651-8f15-15d4e3f6a562",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_user['scrollPercentageHistory'] = df_user['scrollPercentageHistory'].apply(lambda lst: [np.where(x > 100, 100, x) for x in lst])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8245fff6-bee1-498e-9174-d47e3db1ce15",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_user = df_user.loc[:, ['userId', 'history', 'scrollPercentageHistory', 'pageVisitsCountHistory', 'timeOnPageHistory']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7d99ca4e-157d-44ab-8f4d-fb591cb38ded",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 615 ms, sys: 10.1 ms, total: 625 ms\n",
      "Wall time: 626 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_user = df_user.explode(['history', 'scrollPercentageHistory', 'pageVisitsCountHistory', 'timeOnPageHistory'], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c545126d-b7a1-4cb2-803a-dd511e6362d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>history</th>\n",
       "      <th>scrollPercentageHistory</th>\n",
       "      <th>pageVisitsCountHistory</th>\n",
       "      <th>timeOnPageHistory</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>f98d1132f60d46883ce49583257104d15ce723b3bbda21...</td>\n",
       "      <td>c8aab885-433d-4e46-8066-479f40ba7fb2</td>\n",
       "      <td>50.3</td>\n",
       "      <td>2</td>\n",
       "      <td>20380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>f98d1132f60d46883ce49583257104d15ce723b3bbda21...</td>\n",
       "      <td>68d2039c-c9aa-456c-ac33-9b2e8677fba7</td>\n",
       "      <td>18.18</td>\n",
       "      <td>1</td>\n",
       "      <td>21184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>f98d1132f60d46883ce49583257104d15ce723b3bbda21...</td>\n",
       "      <td>13e423ce-1d69-4c78-bc18-e8c8f7271964</td>\n",
       "      <td>16.46</td>\n",
       "      <td>1</td>\n",
       "      <td>35438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2c1080975e257ed630e26679edbe4d5c850c65f3e09f65...</td>\n",
       "      <td>3325b5a1-979a-4cb3-82b6-63905c9edbe8</td>\n",
       "      <td>25.35</td>\n",
       "      <td>1</td>\n",
       "      <td>6049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2c1080975e257ed630e26679edbe4d5c850c65f3e09f65...</td>\n",
       "      <td>fe856057-f97d-419f-ab1c-97c5c3e0719c</td>\n",
       "      <td>45.66</td>\n",
       "      <td>1</td>\n",
       "      <td>210489</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              userId  \\\n",
       "0  f98d1132f60d46883ce49583257104d15ce723b3bbda21...   \n",
       "1  f98d1132f60d46883ce49583257104d15ce723b3bbda21...   \n",
       "2  f98d1132f60d46883ce49583257104d15ce723b3bbda21...   \n",
       "3  2c1080975e257ed630e26679edbe4d5c850c65f3e09f65...   \n",
       "4  2c1080975e257ed630e26679edbe4d5c850c65f3e09f65...   \n",
       "\n",
       "                                 history scrollPercentageHistory  \\\n",
       "0   c8aab885-433d-4e46-8066-479f40ba7fb2                    50.3   \n",
       "1   68d2039c-c9aa-456c-ac33-9b2e8677fba7                   18.18   \n",
       "2   13e423ce-1d69-4c78-bc18-e8c8f7271964                   16.46   \n",
       "3   3325b5a1-979a-4cb3-82b6-63905c9edbe8                   25.35   \n",
       "4   fe856057-f97d-419f-ab1c-97c5c3e0719c                   45.66   \n",
       "\n",
       "  pageVisitsCountHistory timeOnPageHistory  \n",
       "0                      2             20380  \n",
       "1                      1             21184  \n",
       "2                      1             35438  \n",
       "3                      1              6049  \n",
       "4                      1            210489  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_user.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f0cac840-f97f-40b7-97c9-1270f6cd9d4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page</th>\n",
       "      <th>title</th>\n",
       "      <th>issued</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13db0ab1-eea2-4603-84c4-f40a876c7400</td>\n",
       "      <td>caso bruno e dom: 3o suspeito tem prisao tempo...</td>\n",
       "      <td>2022-06-18 20:37:45+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>92907b73-5cd3-4184-8d8c-e206aed2bf1c</td>\n",
       "      <td>linguajar dos santarenos e diferenciado e chei...</td>\n",
       "      <td>2019-06-20 17:19:52+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>61e07f64-cddf-46f2-b50c-ea0a39c22050</td>\n",
       "      <td>ex-premie shinzo abe morre apos ser baleado no...</td>\n",
       "      <td>2022-07-08 08:55:52+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30e2e6c5-554a-48ed-a35f-6c6691c8ac9b</td>\n",
       "      <td>relator no stf, fachin vota contra marco tempo...</td>\n",
       "      <td>2021-09-09 19:06:46+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9dff71eb-b681-40c7-ac8d-68017ac36675</td>\n",
       "      <td>\\napos 2 votos, pedido de vista suspende julga...</td>\n",
       "      <td>2021-09-15 19:16:13+00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   page  \\\n",
       "0  13db0ab1-eea2-4603-84c4-f40a876c7400   \n",
       "1  92907b73-5cd3-4184-8d8c-e206aed2bf1c   \n",
       "2  61e07f64-cddf-46f2-b50c-ea0a39c22050   \n",
       "3  30e2e6c5-554a-48ed-a35f-6c6691c8ac9b   \n",
       "4  9dff71eb-b681-40c7-ac8d-68017ac36675   \n",
       "\n",
       "                                               title                    issued  \n",
       "0  caso bruno e dom: 3o suspeito tem prisao tempo... 2022-06-18 20:37:45+00:00  \n",
       "1  linguajar dos santarenos e diferenciado e chei... 2019-06-20 17:19:52+00:00  \n",
       "2  ex-premie shinzo abe morre apos ser baleado no... 2022-07-08 08:55:52+00:00  \n",
       "3  relator no stf, fachin vota contra marco tempo... 2021-09-09 19:06:46+00:00  \n",
       "4  \\napos 2 votos, pedido de vista suspende julga... 2021-09-15 19:16:13+00:00  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "itens.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8f8311de-dc40-4941-b726-0ffc4d72f54e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "history\n",
       "False    1326291\n",
       "True      100000\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_user.history.isin(itens.page).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25421c95-11ff-4892-9e79-03e431da54b7",
   "metadata": {},
   "source": [
    "Drop values that we don't have informations (news that are not in the database)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "59b59bf9-3e1a-4ded-b92b-5421de29b746",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_user = df_user.loc[df_user.history.isin(itens.page)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9dde8252-248e-44be-83e8-67953f14d57c",
   "metadata": {},
   "outputs": [],
   "source": [
    "itens = itens.loc[itens.page.isin(df_user.history)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "4976ceb7-15cc-4ac8-89de-89433afa278a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique users: 100000\n",
      "Number of unique news: 29492\n",
      "The full rating matrix will have: 2949200000 elements.\n",
      "----------\n",
      "Number of values: 100000\n",
      "Therefore:  0.0033907500339075 % of the matrix is filled.\n",
      "We have an incredibly sparse matrix to work with here.\n",
      "And... as you can imagine, as the number of users and products grow, the number of elements will increase by n*2\n",
      "You are going to need a lot of memory to work with global scale... storing a full matrix in memory would be a challenge.\n",
      "One advantage here is that matrix factorization can realize the rating matrix implicitly, thus we don't need all the data\n"
     ]
    }
   ],
   "source": [
    "# Movie ID to movie name mapping\n",
    "# movie_names = movies_df.set_index('movieId')['title'].to_dict()\n",
    "n_users = len(df_user.userId.unique())\n",
    "n_items = len(df_user.history.unique())\n",
    "print(\"Number of unique users:\", n_users)\n",
    "print(\"Number of unique news:\", n_items)\n",
    "print(\"The full rating matrix will have:\", n_users*n_items, 'elements.')\n",
    "print('----------')\n",
    "print(\"Number of values:\", len(df_user))\n",
    "print(\"Therefore: \", len(df_user) / (n_users*n_items) * 100, '% of the matrix is filled.')\n",
    "print(\"We have an incredibly sparse matrix to work with here.\")\n",
    "print(\"And... as you can imagine, as the number of users and products grow, the number of elements will increase by n*2\")\n",
    "print(\"You are going to need a lot of memory to work with global scale... storing a full matrix in memory would be a challenge.\")\n",
    "print(\"One advantage here is that matrix factorization can realize the rating matrix implicitly, thus we don't need all the data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "c9afefdf-ca43-4244-9978-b8093c701f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch.autograd import Variable\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "class MatrixFactorization(torch.nn.Module):\n",
    "    def __init__(self, n_users, n_items, n_factors=20):\n",
    "        super().__init__()\n",
    "        # create user embeddings\n",
    "        self.user_factors = torch.nn.Embedding(n_users, n_factors) # think of this as a lookup table for the input.\n",
    "        # create item embeddings\n",
    "        self.item_factors = torch.nn.Embedding(n_items, n_factors) # think of this as a lookup table for the input.\n",
    "        self.user_factors.weight.data.uniform_(0, 0.05)\n",
    "        self.item_factors.weight.data.uniform_(0, 0.05)\n",
    "        \n",
    "    def forward(self, data):\n",
    "        # matrix multiplication\n",
    "        users, items = data[:,0], data[:,1]\n",
    "        return (self.user_factors(users)*self.item_factors(items)).sum(1)\n",
    "\n",
    "    \n",
    "    def predict(self, users, items):\n",
    "      if isinstance(users, list):\n",
    "        users = torch.tensor(users)\n",
    "      if isinstance(items, list):\n",
    "        items = torch.tensor(items)\n",
    "    \n",
    "      # Ensure the indices are within range\n",
    "      if users.max() >= self.user_factors.num_embeddings or items.max() >= self.item_factors.num_embeddings:\n",
    "          raise ValueError(\"User or item index out of bounds.\")\n",
    "      \n",
    "      # Stack users and items together\n",
    "      data = torch.stack((users, items), dim=1)  # Shape (N, 2)\n",
    "\n",
    "      if torch.cuda.is_available():\n",
    "          data = data.cuda()  # Move to GPU if necessary\n",
    "\n",
    "      return self.forward(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "4cae9e8d-a38c-4c92-867b-a891836f7c23",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5935/3713295007.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_user['scrollPercentageHistory'] = df_user.scrollPercentageHistory.astype(int)\n"
     ]
    }
   ],
   "source": [
    "df_user['scrollPercentageHistory'] = df_user.scrollPercentageHistory.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "05dd0061-3909-474a-8e1d-d0aa44dc7120",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>history</th>\n",
       "      <th>scrollPercentageHistory</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99995</th>\n",
       "      <td>99995</td>\n",
       "      <td>9460</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>99996</td>\n",
       "      <td>7914</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>99997</td>\n",
       "      <td>29491</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>99998</td>\n",
       "      <td>11936</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>99999</td>\n",
       "      <td>13319</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       userId  history  scrollPercentageHistory\n",
       "0           0        0                       50\n",
       "1           1        1                       25\n",
       "2           2        2                       67\n",
       "3           3        3                       58\n",
       "4           4        4                       78\n",
       "...       ...      ...                      ...\n",
       "99995   99995     9460                       21\n",
       "99996   99996     7914                       55\n",
       "99997   99997    29491                       45\n",
       "99998   99998    11936                        9\n",
       "99999   99999    13319                       44\n",
       "\n",
       "[100000 rows x 3 columns]"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_user.loc[:, ['userId', 'history', 'scrollPercentageHistory']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "b76bd970-d8b8-4355-8862-1065881e7e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the dataloader (necessary for PyTorch)\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from torch.utils.data import DataLoader # package that helps transform your data to machine learning readiness\n",
    "\n",
    "# Note: This isn't 'good' practice, in a MLops sense but we'll roll with this since the data is already loaded in memory.\n",
    "class Loader(Dataset):\n",
    "    def __init__(self):\n",
    "        self.df_user = df_user.loc[:, ['userId', 'history', 'scrollPercentageHistory']].copy()        # Convert all columns to numeric if possible\n",
    "        \n",
    "        # Extract all user IDs and news IDs\n",
    "        users = df_user.userId.unique()\n",
    "        news = df_user.history.unique()\n",
    "        \n",
    "        #--- Producing new continuous IDs for users and news ---\n",
    "        \n",
    "        # Unique values : index\n",
    "        self.userid2idx = {o:i for i,o in enumerate(users)}\n",
    "        self.history2idx = {o:i for i,o in enumerate(news)}\n",
    "        \n",
    "        # Obtained continuous ID for users and news\n",
    "        self.idx2userid = {i:o for o,i in self.userid2idx.items()}\n",
    "        self.idx2history = {i:o for o,i in self.history2idx.items()}\n",
    "        \n",
    "        # return the id from the indexed values as noted in the lambda function down below.\n",
    "        self.df_user.history = df_user.history.apply(lambda x: self.history2idx[x])\n",
    "        self.df_user.userId = df_user.userId.apply(lambda x: self.userid2idx[x])\n",
    "        \n",
    "        \n",
    "        self.x = self.df_user.drop(['scrollPercentageHistory'], axis=1).values\n",
    "        self.y = self.df_user['scrollPercentageHistory'].values\n",
    "        self.x, self.y = torch.tensor(self.x), torch.tensor(self.y) # Transforms the data to tensors (ready for torch models.)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return (self.x[index], self.y[index])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df_user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "2ae78f12-c708-40df-bc6a-89ad205da2f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is running on GPU: True\n",
      "MatrixFactorization(\n",
      "  (user_factors): Embedding(100000, 8)\n",
      "  (item_factors): Embedding(29492, 8)\n",
      ")\n",
      "user_factors.weight tensor([[0.0278, 0.0429, 0.0358,  ..., 0.0032, 0.0193, 0.0430],\n",
      "        [0.0378, 0.0060, 0.0057,  ..., 0.0046, 0.0302, 0.0341],\n",
      "        [0.0049, 0.0040, 0.0325,  ..., 0.0042, 0.0407, 0.0356],\n",
      "        ...,\n",
      "        [0.0020, 0.0117, 0.0178,  ..., 0.0232, 0.0047, 0.0350],\n",
      "        [0.0109, 0.0441, 0.0356,  ..., 0.0301, 0.0399, 0.0321],\n",
      "        [0.0335, 0.0238, 0.0144,  ..., 0.0414, 0.0452, 0.0013]])\n",
      "item_factors.weight tensor([[0.0188, 0.0442, 0.0250,  ..., 0.0485, 0.0028, 0.0443],\n",
      "        [0.0420, 0.0005, 0.0048,  ..., 0.0431, 0.0277, 0.0237],\n",
      "        [0.0326, 0.0098, 0.0438,  ..., 0.0158, 0.0027, 0.0485],\n",
      "        ...,\n",
      "        [0.0482, 0.0069, 0.0381,  ..., 0.0226, 0.0227, 0.0198],\n",
      "        [0.0170, 0.0264, 0.0040,  ..., 0.0259, 0.0292, 0.0283],\n",
      "        [0.0253, 0.0133, 0.0028,  ..., 0.0159, 0.0136, 0.0484]])\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 128\n",
    "cuda = torch.cuda.is_available()\n",
    "\n",
    "print(\"Is running on GPU:\", cuda)\n",
    "\n",
    "model = MatrixFactorization(n_users, n_items, n_factors=8)\n",
    "print(model)\n",
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(name, param.data)\n",
    "# GPU enable if you have a GPU...\n",
    "if cuda:\n",
    "    model = model.cuda()\n",
    "\n",
    "# MSE loss\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "\n",
    "# ADAM optimizier\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "# Train data\n",
    "train_set = Loader()\n",
    "train_loader = DataLoader(train_set, 128, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "dddd4b6f-1bb3-4ea2-80e6-93befc74c2aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5935/59576823.py:1: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for it in tqdm(range(num_epochs)):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7c47d530e234e4b87e76ac06c66645e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/128 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter #0 Loss: 2126.9373334411466\n",
      "iter #1 Loss: 2123.814975123881\n",
      "iter #2 Loss: 2116.0261083734613\n",
      "iter #3 Loss: 2103.9764483907948\n",
      "iter #4 Loss: 2086.901897459689\n",
      "iter #5 Loss: 2066.970797565587\n",
      "iter #6 Loss: 2042.8306222901015\n",
      "iter #7 Loss: 2017.9075404798893\n",
      "iter #8 Loss: 1988.4242844057205\n",
      "iter #9 Loss: 1958.4148728158468\n",
      "iter #10 Loss: 1924.2748648797156\n",
      "iter #11 Loss: 1889.1091291422733\n",
      "iter #12 Loss: 1852.4231024154312\n",
      "iter #13 Loss: 1814.7969941044098\n",
      "iter #14 Loss: 1774.6790819875418\n",
      "iter #15 Loss: 1735.18366961467\n",
      "iter #16 Loss: 1692.729879471957\n",
      "iter #17 Loss: 1650.7318908223106\n",
      "iter #18 Loss: 1608.4928510817115\n",
      "iter #19 Loss: 1565.6093255162543\n",
      "iter #20 Loss: 1522.1981041949728\n",
      "iter #21 Loss: 1479.3636032845968\n",
      "iter #22 Loss: 1436.5617508754096\n",
      "iter #23 Loss: 1394.3983270591482\n",
      "iter #24 Loss: 1351.5104127381464\n",
      "iter #25 Loss: 1310.698928091532\n",
      "iter #26 Loss: 1268.8038730474993\n",
      "iter #27 Loss: 1228.8872382512789\n",
      "iter #28 Loss: 1189.10875645318\n",
      "iter #29 Loss: 1149.7409401037503\n",
      "iter #30 Loss: 1111.609918696801\n",
      "iter #31 Loss: 1074.2976482420627\n",
      "iter #32 Loss: 1038.126377115469\n",
      "iter #33 Loss: 1002.2745885824609\n",
      "iter #34 Loss: 967.6570717111573\n",
      "iter #35 Loss: 934.1765530871613\n",
      "iter #36 Loss: 901.550634750015\n",
      "iter #37 Loss: 869.298749918828\n",
      "iter #38 Loss: 838.1150187226513\n",
      "iter #39 Loss: 807.9427691603561\n",
      "iter #40 Loss: 778.9041956440567\n",
      "iter #41 Loss: 750.9003481267358\n",
      "iter #42 Loss: 722.9361206210788\n",
      "iter #43 Loss: 695.9701167348096\n",
      "iter #44 Loss: 670.1754435663638\n",
      "iter #45 Loss: 644.9845225926861\n",
      "iter #46 Loss: 620.8637145449743\n",
      "iter #47 Loss: 597.1318241909642\n",
      "iter #48 Loss: 574.3864948633686\n",
      "iter #49 Loss: 552.459224183846\n",
      "iter #50 Loss: 531.2582121944183\n",
      "iter #51 Loss: 510.688080536435\n",
      "iter #52 Loss: 490.8638422544045\n",
      "iter #53 Loss: 471.8636256654549\n",
      "iter #54 Loss: 452.83978921251224\n",
      "iter #55 Loss: 434.7804790604145\n",
      "iter #56 Loss: 417.11053140937827\n",
      "iter #57 Loss: 400.7467330776517\n",
      "iter #58 Loss: 384.16863004874693\n",
      "iter #59 Loss: 368.81448413039107\n",
      "iter #60 Loss: 353.57617043107365\n",
      "iter #61 Loss: 338.85893019264006\n",
      "iter #62 Loss: 324.853089159407\n",
      "iter #63 Loss: 311.3282388165174\n",
      "iter #64 Loss: 298.18216532636484\n",
      "iter #65 Loss: 285.34390442206734\n",
      "iter #66 Loss: 273.3219698054711\n",
      "iter #67 Loss: 261.4273666420861\n",
      "iter #68 Loss: 250.0271201365439\n",
      "iter #69 Loss: 239.10244683658377\n",
      "iter #70 Loss: 228.55904138667503\n",
      "iter #71 Loss: 218.51698147122514\n",
      "iter #72 Loss: 208.33199915678605\n",
      "iter #73 Loss: 198.92156216067733\n",
      "iter #74 Loss: 189.91736969130727\n",
      "iter #75 Loss: 180.86679961065502\n",
      "iter #76 Loss: 172.54248762496596\n",
      "iter #77 Loss: 164.15800460464203\n",
      "iter #78 Loss: 156.44060962218458\n",
      "iter #79 Loss: 148.60215691471345\n",
      "iter #80 Loss: 141.26573042613467\n",
      "iter #81 Loss: 134.54519606978081\n",
      "iter #82 Loss: 127.44115322142306\n",
      "iter #83 Loss: 120.95412601168503\n",
      "iter #84 Loss: 114.66579409694428\n",
      "iter #85 Loss: 108.6433175494299\n",
      "iter #86 Loss: 103.03085051290215\n",
      "iter #87 Loss: 97.48320377574248\n",
      "iter #88 Loss: 92.0490462505604\n",
      "iter #89 Loss: 86.96355254570847\n",
      "iter #90 Loss: 82.2189281761189\n",
      "iter #91 Loss: 77.42260333034389\n",
      "iter #92 Loss: 72.85872069222238\n",
      "iter #93 Loss: 68.63031161105846\n",
      "iter #94 Loss: 64.63467858453541\n",
      "iter #95 Loss: 60.618189553775444\n",
      "iter #96 Loss: 56.84245938047424\n",
      "iter #97 Loss: 53.26475080504747\n",
      "iter #98 Loss: 49.913180986023924\n",
      "iter #99 Loss: 46.643468483634614\n",
      "iter #100 Loss: 43.54266495960753\n",
      "iter #101 Loss: 40.60627870425544\n",
      "iter #102 Loss: 37.927406126504664\n",
      "iter #103 Loss: 35.19689234778704\n",
      "iter #104 Loss: 32.70424643608615\n",
      "iter #105 Loss: 30.345770060101433\n",
      "iter #106 Loss: 28.101922702301493\n",
      "iter #107 Loss: 25.981825049423502\n",
      "iter #108 Loss: 23.992034378830734\n",
      "iter #109 Loss: 22.132829996249864\n",
      "iter #110 Loss: 20.361034623573502\n",
      "iter #111 Loss: 18.741609147518798\n",
      "iter #112 Loss: 17.150903802431756\n",
      "iter #113 Loss: 15.722433115096043\n",
      "iter #114 Loss: 14.355363722461874\n",
      "iter #115 Loss: 13.09704606296004\n",
      "iter #116 Loss: 11.895553703960555\n",
      "iter #117 Loss: 10.81663523362878\n",
      "iter #118 Loss: 9.800315765506776\n",
      "iter #119 Loss: 8.847427732842352\n",
      "iter #120 Loss: 7.978134740344094\n",
      "iter #121 Loss: 7.181412783025018\n",
      "iter #122 Loss: 6.4592912995525635\n",
      "iter #123 Loss: 5.77621971714832\n",
      "iter #124 Loss: 5.163295202243054\n",
      "iter #125 Loss: 4.597219272171293\n",
      "iter #126 Loss: 4.091445296907517\n",
      "iter #127 Loss: 3.6233993766405392\n"
     ]
    }
   ],
   "source": [
    "for it in tqdm(range(num_epochs)):\n",
    "    losses = []\n",
    "    for x, y in train_loader:\n",
    "         if cuda:\n",
    "            x, y = x.cuda(), y.cuda()\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(x)\n",
    "            loss = loss_fn(outputs.squeeze(), y.type(torch.float32))\n",
    "            losses.append(loss.item())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    print(\"iter #{}\".format(it), \"Loss:\", sum(losses) / len(losses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "5799e27d-c27d-4028-a377-674e5f2ef0f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_factors.weight tensor([[1.0519, 1.0663, 1.0602,  ..., 1.0264, 1.0439, 1.0665],\n",
      "        [0.9789, 0.9509, 0.9508,  ..., 0.9451, 0.9734, 0.9777],\n",
      "        [0.9724, 0.9717, 0.9993,  ..., 0.9721, 1.0088, 1.0026],\n",
      "        ...,\n",
      "        [2.3638, 2.3777, 2.3885,  ..., 2.3884, 2.3703, 2.3915],\n",
      "        [0.5787, 0.6114, 0.6035,  ..., 0.5972, 0.6051, 0.6000],\n",
      "        [2.1382, 2.1291, 2.1177,  ..., 2.1453, 2.1478, 2.1111]],\n",
      "       device='cuda:0')\n",
      "item_factors.weight tensor([[5.8937, 5.9036, 5.8831,  ..., 5.9030, 5.8840, 5.8691],\n",
      "        [3.3066, 3.2317, 3.2267,  ..., 3.2962, 3.3094, 3.2561],\n",
      "        [8.4699, 8.4748, 8.5163,  ..., 8.4476, 8.4367, 8.5377],\n",
      "        ...,\n",
      "        [3.0077, 2.9593, 2.9883,  ..., 2.9714, 2.9753, 2.9738],\n",
      "        [2.9910, 3.0128, 2.9794,  ..., 2.9997, 3.0096, 3.0104],\n",
      "        [2.3965, 2.3800, 2.3669,  ..., 2.3786, 2.3833, 2.4080]],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# By training the model, we will have tuned latent factors for movies and users.\n",
    "c = 0\n",
    "uw = 0\n",
    "iw = 0 \n",
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(name, param.data)\n",
    "        if c == 0:\n",
    "          uw = param.data\n",
    "          c +=1\n",
    "        else:\n",
    "          iw = param.data\n",
    "        #print('param_data', param_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "6ee98241-55df-4c25-aa77-28fe1190841e",
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_embeddings = model.item_factors.weight.data.cpu().numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "67310525-d13b-4a5f-9402-5e67ded53714",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.8937235, 5.9035664, 5.8831077, ..., 5.9030147, 5.884031 ,\n",
       "        5.8691177],\n",
       "       [3.306555 , 3.2316678, 3.22666  , ..., 3.2961702, 3.3093953,\n",
       "        3.2560558],\n",
       "       [8.469858 , 8.474832 , 8.516283 , ..., 8.447589 , 8.436699 ,\n",
       "        8.53773  ],\n",
       "       ...,\n",
       "       [3.00767  , 2.9592712, 2.9882865, ..., 2.9714386, 2.975317 ,\n",
       "        2.9738262],\n",
       "       [2.991031 , 3.012831 , 2.9794354, ..., 2.9997416, 3.0096095,\n",
       "        3.010377 ],\n",
       "       [2.3965068, 2.3799865, 2.3668928, ..., 2.3785949, 2.38332  ,\n",
       "        2.4080062]], shape=(29492, 8), dtype=float32)"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trained_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "fdf3ffc8-dadb-4e05-9197-22c35bdb2b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.cluster import KMeans\n",
    "# Fit the clusters based on the movie weights\n",
    "kmeans = KMeans(n_clusters=10, random_state=0).fit(trained_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "397a91d3-51f5-4ba9-af6b-40fe0bd079af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster #0\n",
      "- o que a australia esta fazendo para combater os devastadores incendios florestais\n",
      "- mariana: quase um ano e meio apos prazo, somente 47 casas de atingidos foram construidas\n",
      "- instagram adiciona opcao para colocar musica em fotos do feed; veja como fazer\n",
      "- litoral do rn tem 16 trechos de praias improprios para banho; confira locais\n",
      "- escolas de aplicacao da upe abrem inscricoes para 388 vagas em quatro cidades; veja como se cadastrar\n",
      "- psd confirma pre-candidatura do prefeito de sao jose dos campos, felicio ramuth, ao governo do estado\n",
      "- de crime a arte: a historia do grafite nas ruas de sao paulo\n",
      "- poucas horas apos atentado em trapiche, paranagua registra mais tres assassinatos, diz policia\n",
      "- ibovespa fecha em alta pelo 6o pregao seguido\n",
      "- empresaria de fernando de noronha fatima queiroz morre no recife \n",
      "Cluster #1\n",
      "- como fazer o emprestimo do auxilio brasil?\n",
      "- video: pms executam foragido da justica apos homem colocar as maos na cabeca\n",
      "- desemprego recua para 9,3% em junho, mas numero de informais e recorde, aponta ibge\n",
      "- zagueiro renan, do bragantino, se envolve em acidente com morte; jogador tinha sinais de embriaguez\n",
      "- eua relaxam medidas de prevencao a covid-19 e eliminam quarentenas\n",
      "- 'falei para ele que nao gostava, que tinha medo', diz esposa de colecionador de arma morto por tiro acidental em jacarei, sp\n",
      "- como se cadastrar para receber o auxilio caminhoneiro?\n",
      "- com 23 votos favoraveis, renato freitas perde mandato na camara de curitiba por quebra de decoro\n",
      "- +milionaria; concurso 12: ninguem vence e premio acumula em r$ 11,5 milhoes\n",
      "- entenda por que o preco do diesel nao cai, mesmo com recuo dos combustiveis\n",
      "Cluster #2\n",
      "- autor do disparo que atingiu por engano mulher em mg se entrega e policia investiga caso\n",
      "- baleia e flagrada saltando no mar de boa viagem, no recife: 'foi emocionante', diz moradora que filmou momento\n",
      "- 'ganho r$ 2,5 mil e devo r$ 16 mil por mes': g1 acompanha programa de planejamento financeiro\n",
      "- bode pode ser 'vilao' da desertificacao ou fonte de renda sustentavel na caatinga\n",
      "- salmonela: entenda o que e a bacteria detectada em chocolates na europa\n",
      "- policia federal cumpre 43 mandados em operacao contra faccao criminosa em roraima\n",
      "- cliente e esfaqueado e morto enquanto aguardava para cortar o cabelo em barbearia em mt\n",
      "- o que e a arquitetura passiva, com casas onde nao se passa calor nem frio e que quase nao consomem energia\n",
      "- brasil e um dos paises que menos investiram em educacao na pandemia, diz ocde\n",
      "- adelio, autor da facada em bolsonaro, passa por nova pericia medica e laudo saira em ate 30 dias \n",
      "Cluster #3\n",
      "- agosto lilas: itapetininga promove palestras de conscientizacao sobre a violencia domestica\n",
      "- entenda os perigos das noticias falsas\n",
      "- pdt anuncia vice-prefeita de salvador como candidata a vice-presidente na chapa de ciro gomes\n",
      "- cavalo cai sozinho no asfalto de nova york, e militantes pedem proibicao de charretes turisticas; veja video\n",
      "- saiba quais sao os bairros mais caros para se morar em bh\n",
      "- mais de 1,3 mil recenseadores recebem treinamento em 93 municipios do tocantins\n",
      "- pesquisa descobre 'cidades' da era pre-colonial na amazonia com piramides de ate 22 metros de altura\n",
      "- juiza manda soltar suspeitos de sequestrar e matar jovem por engano em 'tribunal do crime' no piaui\n",
      "- brasil registra 210 mortes por covid nas ultimas 24 horas; total de obitos ultrapassa 680 mil\n",
      "- jovem e estuprada por 3 homens dentro de carro na zona norte de macapa\n",
      "Cluster #4\n",
      "- exclusivo: video mostra salto de aluno de paraquedismo que terminou em morte em boituva\n",
      "- brasileiro agride comissaria, e voo que ia de sao paulo a nova york faz pouso nao programado; veja imagens\n",
      "- bolsonaro edita decreto que regulamenta credito consignado a quem ganha auxilio brasil\n",
      "- joao paulo diniz morre aos 58 anos em paraty\n",
      "- tse exclui de grupo de fiscalizacao coronel que divulgou fake news sobre urnas\n",
      "- em encontro cordial, bolsonaro diz a moraes querer eleicoes 'transparentes e tranquilas'\n",
      "- mulher do cantor george henrique sofreu crime sexual durante exame em hospital de goiania, diz assessoria\n",
      "- 'todos tem medo': o bilionario russo que se atreve a denunciar putin\n",
      "- familia de bebe que tomou vacina contra covid por engano entra na justica contra a prefeitura de sorocaba\n",
      "- noivos sao roubados apos festa de casamento e ficam sem aliancas, presentes ainda embrulhados e dinheiro da gravata\n",
      "Cluster #5\n",
      "- acre deixou de receber mais de r$ 130 milhoes do fundeb devido a pandemia \n",
      "- trf-2 tranca acao penal contra raphael montenegro, ex-secretario de administracao penitenciaria\n",
      "- araucaria tambem e afetada pelo desabastecimento de medicamentos no parana\n",
      "- confusao em bar perto da unicamp gera panico e alunos relatam tiros, agressao e simbolo nazista, em campinas\n",
      "- condenados em 2011, pilotos do jato legacy envolvidos em acidente do voo 1097 tem prisao decretada em mt\n",
      "- unidade de fisioterapia e terapia ocupacional da uepa oferece atendimento de reabilitacao para diversas faixas etarias\n",
      "- genero 'nao binarie' e incluido em certidoes de nascimento no rio\n",
      "- motorista particular morre baleado e passageiro fica ferido em santo antonio de posse\n",
      "- video mostra briga por causa de latido de cao que terminou com homem baleado por guarda municipal\n",
      "- homem e mulher morrem em acidente de moto em santa cruz do capibaribe; veja video do momento\n",
      "Cluster #6\n",
      "- voce viu? 'musa das estradas' faz video de pe, primo que salvou crianca e as mais lidas do g1 sc\n",
      "- quadro de tarsila do amaral avaliado em r$ 250 milhoes e encontrado embaixo da cama de preso por golpe milionario; veja video\n",
      "- 'roda de carro': telescopio james webb divulga imagem de galaxia de aparencia curiosa\n",
      "- superiate italiano de r$120 milhoes  pega fogo na costa da espanha\n",
      "- laudo aponta que advogado levou 7 facadas e morreu apos golpe fatal no torax\n",
      "- advogado entra na justica para reconhecer enteados como filhos: 'alem do laco eterno de amor, nosso sobrenome e o mesmo'\n",
      "- curitiba, goiania e salvador terao 5g a partir de terca, diz anatel; rio, vitoria, florianopolis e palmas, ate setembro\n",
      "- o impacto dos produtos de limpeza na natureza\n",
      "- taiwan inicia manobras militares com municao real e simula defesa contra ataque chines\n",
      "- salman rushdie: o que se sabe sobre o homem acusado pelo ataque contra o escritor em nova york\n",
      "Cluster #7\n",
      "- 'estou arrependido. fui covarde', diz homem suspeito de matar ex-namorada em belo horizonte\n",
      "- video: 'me ajuda, por favor! nao! socorro!', suplicou influenciadora; vanderlei bambam foi preso em flagrante por agredir a namorada\n",
      "- jovem conta ter gastado r$ 9 mil apos tomar zolpidem; entenda o que e o medicamento e os riscos\n",
      "- motorista de land rover atropela e mata jovem apos confusao em estacionamento de casa noturna \n",
      "- ato pela democracia recorda mortos na  ditadura, pede respeito ao sistema eleitoral e leva multidao ao centro de sp\n",
      "- salman rushdie, autor de 'versos satanicos' e jurado de morte pelo ira, e esfaqueado por homem nos eua\n",
      "- atirador em montenegro mata 11 apos briga familiar, diz imprensa local\n",
      "- jardineiro cai no mar, e arrastado por correnteza e fica isolado por 5 dias em ilha no rio \n",
      "- policial militar e morto com tiro na cabeca em iraja, no rio\n",
      "- adolescente de 12 anos vitima de estupro coletivo na ba saiu da escola apos 'virar chacota' entre os suspeitos, diz pai da jovem\n",
      "Cluster #8\n",
      "- stanley's hair institute e a primeira clinica brasileira a implementar o metaverso na area da saude\n",
      "- governo do rj diminui icms para gasolina no estado; preco do litro vai baixar para r$ 6,61\n",
      "- estudante matheusa foi 'julgada' antes de ser morta por traficantes, diz delegada\n",
      "- sine maceio oferta mais de 200 vagas de emprego nesta segunda-feira \n",
      "- emprego dos sonhos: empresa oferece r$ 400 mil por ano para 'testador' provar 3,5 mil doces todo mes\n",
      "- eua autorizam reforco de vacina da pfizer contra covid para adolescentes de 12 a 15 anos\n",
      "- mulher e agredida durante assalto no jardim rodeio, em mogi\n",
      "- inmetro solicita que industrias texteis se ajustem a novo regulamento para as etiquetas  \n",
      "- exclusivo: armas compradas legalmente vao parar nas maos de criminosos, aponta levantamento\n",
      "- variola dos macacos: em 4 dias, saude confirma mais 9 casos no df\n",
      "Cluster #9\n",
      "- mp eleitoral vai a justica para impugnar candidatura de washington reis, vice de castro \n",
      "- mascaras em aeroportos e avioes: veja 10 perguntas e respostas divulgadas pela anvisa \n",
      "- ios 16: iphones 6s e 7 ficam sem o novo sistema operacional \n",
      "- apos reclamacao de bolsonaro, proposta que amplia isencao de ir e incluida em plano de governo\n",
      "- enem 2017: leia redacoes nota mil \n",
      "- movimentos sociais e estudantes fazem protesto pela democracia na avenida paulista\n",
      "- mega-sena, concurso 2.498: aposta simples de blumenau (sc) acerta as seis dezenas e fatura sozinha r$ 51,8 milhoes \n",
      "- policia federal faz operacao contra quadrilha de trafico internacional de drogas\n",
      "- ministerio publico solicita suspensao de shows com wesley safadao e raca negra em nova russas, no ceara\n",
      "- pm da tapas no rosto de cliente de distribuidora durante abordagem, em aparecida de goiania; video\n"
     ]
    }
   ],
   "source": [
    "'''It can be seen here that the new that are in the same cluster tend to have\n",
    "similar genres. Also note that the algorithm is unfamiliar with the news name\n",
    "and only obtained the relationships by looking at the numbers representing how\n",
    "users have responded to the movie selections.'''\n",
    "for cluster in range(10):\n",
    "    print(\"Cluster #{}\".format(cluster))\n",
    "    news = []\n",
    "    # Find movie indices belonging to the current cluster\n",
    "    count = 0\n",
    "    for newdx in np.where(kmeans.labels_ == cluster)[0]:\n",
    "        movid = train_set.idx2history[newdx]\n",
    "        news_title = df_user.loc[df_user.history == int(movid)].history_.values[0]\n",
    "        news_title = itens.loc[itens.page == news_title].title.item()\n",
    "        news.append(news_title)\n",
    "        count += 1\n",
    "        if count == 10:\n",
    "            for i in news:\n",
    "                print('-',  i)\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "8a5c3f2e-a640-4318-86bf-af03afd0fef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('test_top10_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "3461a2ea-11d3-465f-b28f-8f355ae2baa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "test['cold'] = True\n",
    "test.loc[test.userId.isin(df_user.user_id), 'cold'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "6cf11f0f-dbe0-40db-90eb-98c07d6eab26",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test.loc[test.acessos_futuros.isin(itens.page)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "2e5abc40-ace8-4462-9c12-a5b6c01fdd72",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_test = test.loc[test['cold'] == False].sample().userId.item()\n",
    "news = list(test.loc[test.userId == user_test].acessos_futuros.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "17d56139-22b5-4bec-9403-c00b02cbc9f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "user = [int(df_user.loc[df_user.user_id == user_test].userId.values[0]) for _ in news]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "6c6e8281-fed9-445b-811e-3340b4128c7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([88509, 88509, 88509, 88509, 88509, 88509, 88509, 88509, 88509, 88509],\n",
       " ['d730c4a6-e8f6-4fde-b73a-afbe148479cd',\n",
       "  '41742d22-1763-4602-9298-4d87b1a39ea1',\n",
       "  '8a042ffb-2801-4c72-a8ff-63a9a2205bd2',\n",
       "  'd7f17a3c-3885-4b47-95a8-c4204a3698f5',\n",
       "  '29b6b142-4173-4ec4-832f-7d0a32255c10',\n",
       "  '7fbc5d9e-c135-49c2-8f71-440b1516b6a8',\n",
       "  'b7f30490-0b67-4ccc-b032-1eeeb179b464',\n",
       "  '9354e2df-4607-4108-b818-dba6b5a94133',\n",
       "  '51219799-daab-48b2-b700-3a61833b3ea8',\n",
       "  '82206221-05a0-4f89-aa10-e8c8dc0cc418'])"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user, news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "8cbb41d7-9cfe-4db1-9a81-7636a840eacd",
   "metadata": {},
   "outputs": [],
   "source": [
    "news2 = list(df_user.loc[df_user.history_.isin(news), ['history', 'history_']].drop_duplicates().history.values)\n",
    "news2 = [int(i) for i in news2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "6efa5712-0a86-4f22-8b20-7d5d37fb8209",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([88509, 88509, 88509, 88509, 88509, 88509, 88509, 88509, 88509, 88509],\n",
       " [40, 57, 69, 157, 236, 844, 940, 2604, 2858, 3476])"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user, news2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "13b5ae7e-58b5-4597-80d8-dcbbdc15f72b",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument index in method wrapper_CUDA__index_select)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[255]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Predict ratings\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnews2\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[118]\u001b[39m\u001b[32m, line 38\u001b[39m, in \u001b[36mMatrixFactorization.predict\u001b[39m\u001b[34m(self, users, items)\u001b[39m\n\u001b[32m     35\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch.cuda.is_available():\n\u001b[32m     36\u001b[39m     data = data.cuda()  \u001b[38;5;66;03m# Move to GPU if necessary\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m38\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[118]\u001b[39m\u001b[32m, line 19\u001b[39m, in \u001b[36mMatrixFactorization.forward\u001b[39m\u001b[34m(self, data)\u001b[39m\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, data):\n\u001b[32m     17\u001b[39m     \u001b[38;5;66;03m# matrix multiplication\u001b[39;00m\n\u001b[32m     18\u001b[39m     users, items = data[:,\u001b[32m0\u001b[39m], data[:,\u001b[32m1\u001b[39m]\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43muser_factors\u001b[49m\u001b[43m(\u001b[49m\u001b[43musers\u001b[49m\u001b[43m)\u001b[49m*\u001b[38;5;28mself\u001b[39m.item_factors(items)).sum(\u001b[32m1\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/c/Users/lucas/Downloads/challenge-webmedia-e-globo-2023/myenv/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1734\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1735\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1736\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/c/Users/lucas/Downloads/challenge-webmedia-e-globo-2023/myenv/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1742\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1743\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1744\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1745\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1746\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1747\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1749\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1750\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/c/Users/lucas/Downloads/challenge-webmedia-e-globo-2023/myenv/lib/python3.12/site-packages/torch/nn/modules/sparse.py:190\u001b[39m, in \u001b[36mEmbedding.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    189\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m190\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    191\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    192\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    193\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    194\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmax_norm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    195\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnorm_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    196\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    197\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    198\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/c/Users/lucas/Downloads/challenge-webmedia-e-globo-2023/myenv/lib/python3.12/site-packages/torch/nn/functional.py:2551\u001b[39m, in \u001b[36membedding\u001b[39m\u001b[34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[39m\n\u001b[32m   2545\u001b[39m     \u001b[38;5;66;03m# Note [embedding_renorm set_grad_enabled]\u001b[39;00m\n\u001b[32m   2546\u001b[39m     \u001b[38;5;66;03m# XXX: equivalent to\u001b[39;00m\n\u001b[32m   2547\u001b[39m     \u001b[38;5;66;03m# with torch.no_grad():\u001b[39;00m\n\u001b[32m   2548\u001b[39m     \u001b[38;5;66;03m#   torch.embedding_renorm_\u001b[39;00m\n\u001b[32m   2549\u001b[39m     \u001b[38;5;66;03m# remove once script supports set_grad_enabled\u001b[39;00m\n\u001b[32m   2550\u001b[39m     _no_grad_embedding_renorm_(weight, \u001b[38;5;28minput\u001b[39m, max_norm, norm_type)\n\u001b[32m-> \u001b[39m\u001b[32m2551\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mRuntimeError\u001b[39m: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument index in method wrapper_CUDA__index_select)"
     ]
    }
   ],
   "source": [
    "# Predict ratings\n",
    "model.predict(user, news2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "4d9d0f4f-4b94-4340-bab4-958af444c174",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and mappings saved successfully.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pickle\n",
    "\n",
    "# Save model weights\n",
    "torch.save(model.state_dict(), \"model.pth\")\n",
    "\n",
    "# Save mappings\n",
    "mappings = {\n",
    "    \"userid2idx\": train_set.userid2idx,\n",
    "    \"history2idx\": train_set.history2idx,\n",
    "    \"idx2userid\": train_set.idx2userid,\n",
    "    \"idx2history\": train_set.idx2history,\n",
    "}\n",
    "\n",
    "with open(\"mappings.pkl\", \"wb\") as f:\n",
    "    pickle.dump(mappings, f)\n",
    "\n",
    "print(\"Model and mappings saved successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "d87857f3-152a-46e0-8e72-1875187b2afa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.user_factors.embedding_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "8be8526e-ed0c-4c88-bc43-b3d5f3d49461",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of users: 100000\n",
      "Number of movies: 29492\n"
     ]
    }
   ],
   "source": [
    "# Get the number of users and movies from the mappings\n",
    "n_users = len(mappings[\"userid2idx\"])\n",
    "n_items = len(mappings[\"history2idx\"])\n",
    "\n",
    "print(f\"Number of users: {n_users}\")\n",
    "print(f\"Number of movies: {n_items}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "bbf511bf-9a7e-4742-b254-b0d970f15cf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "6abc3e8f-7c14-4b5f-91cd-40225789ec94",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5935/3181244412.py:14: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(\"model.pth\", map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and mappings loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "## How to use it\n",
    "\n",
    "import torch\n",
    "import pickle\n",
    "\n",
    "# Define the same model structure\n",
    "n_users = 100000  # Replace with actual number of users\n",
    "n_items = 29492  # Replace with actual number of items\n",
    "n_factors = 8\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# Load the model\n",
    "model = MatrixFactorization(n_users, n_items, n_factors).to(device)\n",
    "model.load_state_dict(torch.load(\"model.pth\", map_location=device))\n",
    "model.eval()\n",
    "\n",
    "# Ensure inputs are on the correct device\n",
    "user_tensor = torch.tensor([user], device=device)\n",
    "news_tensor = torch.tensor([news2], device=device)\n",
    "\n",
    "# Load the mappings\n",
    "with open(\"mappings.pkl\", \"rb\") as f:\n",
    "    mappings = pickle.load(f)\n",
    "\n",
    "userid2idx = mappings[\"userid2idx\"]\n",
    "movieid2idx = mappings[\"history2idx\"]\n",
    "idx2userid = mappings[\"idx2userid\"]\n",
    "idx2movieid = mappings[\"idx2history\"]\n",
    "\n",
    "print(\"Model and mappings loaded successfully.\")\n",
    "\n",
    "print(user, news2)\n",
    "response = model.predict(user, news2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "29237abc-fe35-4dd9-970c-5c8ec3b3b7ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[88509, 88509, 88509, 88509, 88509, 88509, 88509, 88509, 88509, 88509] [40, 57, 69, 157, 236, 844, 940, 2604, 2858, 3476]\n"
     ]
    }
   ],
   "source": [
    "print(user, news2)\n",
    "response = model.predict(user, news2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "7cf5d63b-ac5e-4f69-aacf-63c81ebf5552",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[32, 31, 38, 27, 29, 36, 8, 22, 13, 23]"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[int(i) for i in response]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "f2075254-0461-42fb-a6f8-f00cbb9cff4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{88509: 3476}"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(zip(user, news2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "6a339f81-d113-4c0b-91b0-f303d51873e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 4, 2: 5, 3: 6}"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(zip([1,2,3], [4,5,6]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "6070ed92-be3b-4255-8758-ffd7628feb1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_user.to_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "76007b5e-cf80-4a67-a49e-3056658320e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "itens.to_csv('itens_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27183adf-3f4f-4e8f-8c1f-9370d8baf9c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
